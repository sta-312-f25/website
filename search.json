[
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Troubleshooting",
    "section": "",
    "text": "Problem: I cannot log in.\n\nDouble-check that you are using your school email and the correct password.\n\nProblem: My session is stuck in ‚ÄúQueued‚Äù.\n\nRefresh your page\n\nWait a few minutes; this can happen when servers are busy.\n\nIf it does not start after 2 minutes, try logging out and back in.\n\nProblem: RStudio crashes or disconnects.\n\nTry reducing the number of hours when launching your session.\n\nMake sure you have a stable internet connection.\n\nProblem: Quarto is not rendering.\n\nCheck that you saved your file with the .qmd extension.\n\nVerify that Quarto is installed by running quarto --version in the RStudio terminal.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "slides/03-slides.html#before-you-fit-a-model",
    "href": "slides/03-slides.html#before-you-fit-a-model",
    "title": "Linear Regression Fundamentals",
    "section": "Before You Fit a Model",
    "text": "Before You Fit a Model\n\nüìñ Understand the content matter\nAs a statistician I collaborate frequently with subject matter experts to ensure that I understand the context of the problem at hand.\n\n\n‚ùì Understand the objective\nIt is crucial to understand what the objectives are. Ideally, these are set a priori, or if exploratory analyses are being done that is very explicit from beginning to end."
  },
  {
    "objectID": "slides/03-slides.html#before-you-fit-a-model-1",
    "href": "slides/03-slides.html#before-you-fit-a-model-1",
    "title": "Linear Regression Fundamentals",
    "section": "Before You Fit a Model",
    "text": "Before You Fit a Model\n\nüìè Understand where the data came from\nWas this observational or experimental data? Is any data missing? What are the units? Are there data entry issues?\n\n\nüßπ Get the data into a tidy, analyzable form\nOften we get data in a form that is not easily analyzable. In this class, we will be focusing mostly on statistical methodology once the data is in an analyzable format, but just because it is analyzable doesn‚Äôt mean the analysis choice is obvious."
  },
  {
    "objectID": "slides/03-slides.html#before-you-fit-a-model-2",
    "href": "slides/03-slides.html#before-you-fit-a-model-2",
    "title": "Linear Regression Fundamentals",
    "section": "Before You Fit a Model",
    "text": "Before You Fit a Model\nüíÉ Determine the appropriate model\nIn this class we are focusing on Linear Models. Linear models are not always appropriate. You must examine your data to determine whether a linear model is a good choice."
  },
  {
    "objectID": "slides/03-slides.html#is-a-linear-model-appropriate",
    "href": "slides/03-slides.html#is-a-linear-model-appropriate",
    "title": "Linear Regression Fundamentals",
    "section": "Is a Linear Model Appropriate?",
    "text": "Is a Linear Model Appropriate?\n\nOutcome variable, \\(y\\) is continuous\nExplanatory variable(s), \\(X = \\{X_1, ..., X_p\\}\\) can take any form\nObservations are independent\nThe residuals are homoscedastic (Equal variance)\nThe residuals are normally distributed\nThe relationship between \\(X\\) and \\(y\\) is linear"
  },
  {
    "objectID": "slides/03-slides.html#calculating-a-sample-average",
    "href": "slides/03-slides.html#calculating-a-sample-average",
    "title": "Linear Regression Fundamentals",
    "section": "Calculating a sample average",
    "text": "Calculating a sample average\n\\[\\bar{Y}=\\frac{1}{N}\\sum_{i=1}^NY_i\\]\n\nHow could we write this using matrices?"
  },
  {
    "objectID": "slides/03-slides.html#calculating-a-sample-average-1",
    "href": "slides/03-slides.html#calculating-a-sample-average-1",
    "title": "Linear Regression Fundamentals",
    "section": "Calculating a sample average",
    "text": "Calculating a sample average\n\\[\\mathbf{A} = \\begin{bmatrix}1 \\\\ 1 \\\\ \\vdots \\\\ 1\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/03-slides.html#calculating-a-sample-average-2",
    "href": "slides/03-slides.html#calculating-a-sample-average-2",
    "title": "Linear Regression Fundamentals",
    "section": "Calculating a sample average",
    "text": "Calculating a sample average\n\\[\\frac{1}{N}\\mathbf{A}^TY = \\frac{1}{N}\\begin{bmatrix}1 & 1 & ... & 1\\end{bmatrix}\\begin{bmatrix}Y_1\\\\Y_2\\\\\\vdots\\\\Y_n\\end{bmatrix}=\\bar{Y}\\]"
  },
  {
    "objectID": "slides/03-slides.html#in-r",
    "href": "slides/03-slides.html#in-r",
    "title": "Linear Regression Fundamentals",
    "section": " In R",
    "text": "In R\n\nset.seed(1)\n\ny &lt;- rnorm(100)\nN &lt;- length(y)\nY &lt;- matrix(y, nrow = N)\nA &lt;- matrix(1, nrow = N)\nt(A) %*% Y / N\n\n          [,1]\n[1,] 0.1088874\n\nmean(Y)\n\n[1] 0.1088874"
  },
  {
    "objectID": "slides/03-slides.html#calculating-a-variance",
    "href": "slides/03-slides.html#calculating-a-variance",
    "title": "Linear Regression Fundamentals",
    "section": "Calculating a Variance",
    "text": "Calculating a Variance\n\\[\\frac{1}{N}\\sum_{i=1}^N(Y_i-\\bar{Y})^2\\]\n\nHow could we write this using matrices"
  },
  {
    "objectID": "slides/03-slides.html#calculating-a-variance-1",
    "href": "slides/03-slides.html#calculating-a-variance-1",
    "title": "Linear Regression Fundamentals",
    "section": "Calculating a Variance",
    "text": "Calculating a Variance\n\\[\\mathbf{e} = \\begin{bmatrix}Y_1 - \\bar{Y}\\\\\\vdots \\\\Y_N-\\bar{Y}\\end{bmatrix}, \\frac{1}{N}\\mathbf{e}^T\\mathbf{e} = \\frac{1}{N}\\sum_{i=1}^N(Y_i-\\bar{Y})^2\\]"
  },
  {
    "objectID": "slides/03-slides.html#in-r-1",
    "href": "slides/03-slides.html#in-r-1",
    "title": "Linear Regression Fundamentals",
    "section": " In R",
    "text": "In R\n\nMultiplying a transpose of a matrix with another matrix is very common\n\nBecause R was made by and for statisticians, there is a function for this: crossprod\n\n\ncrossprod(A, Y) / N\n\n          [,1]\n[1,] 0.1088874"
  },
  {
    "objectID": "slides/03-slides.html#in-r-2",
    "href": "slides/03-slides.html#in-r-2",
    "title": "Linear Regression Fundamentals",
    "section": " In R",
    "text": "In R\n\nYou can just put one matrix if you want the transpose of a matrix multiplied by itself\n\n\nY_bar &lt;- crossprod(A, Y) / N\ne &lt;- y - c(Y_bar)\ncrossprod(e) / N\n\n          [,1]\n[1,] 0.7986945"
  },
  {
    "objectID": "slides/03-slides.html#the-linear-model",
    "href": "slides/03-slides.html#the-linear-model",
    "title": "Linear Regression Fundamentals",
    "section": "The Linear Model",
    "text": "The Linear Model\n\n\nStandard form: \\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\]\n\n\n\nWhere:\n\n\\(\\mathbf{y}\\) is an \\(n \\times 1\\) vector of responses\n\n\\(\\mathbf{X}\\) is an \\(n \\times p\\) design matrix\n\n\\(\\boldsymbol{\\beta}\\) is a \\(p \\times 1\\) vector of parameters\n\n\\(\\boldsymbol{\\varepsilon}\\) is an \\(n \\times 1\\) vector of errors"
  },
  {
    "objectID": "slides/03-slides.html#the-design-matrix",
    "href": "slides/03-slides.html#the-design-matrix",
    "title": "Linear Regression Fundamentals",
    "section": "The Design Matrix",
    "text": "The Design Matrix\n\nSimple linear regression: \\[\\mathbf{X} = \\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix}, \\quad \\boldsymbol{\\beta} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/03-slides.html#the-design-matrix-1",
    "href": "slides/03-slides.html#the-design-matrix-1",
    "title": "Linear Regression Fundamentals",
    "section": "The Design Matrix",
    "text": "The Design Matrix\nMultiple regression: \\[\\mathbf{X} = \\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/03-slides.html#what-about-hats",
    "href": "slides/03-slides.html#what-about-hats",
    "title": "Linear Regression Fundamentals",
    "section": "What About Hats?",
    "text": "What About Hats?\n\nHat notation indicates estimates or predicted values\n\n\nParameters vs.¬†Estimates:\n\n\\(\\beta_0, \\beta_1\\) = true (unknown) parameters\n\n\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\) = estimated parameters from data\n\n\n\n\nObserved vs.¬†Predicted:\n\n\\(y_i\\) = observed response values\n\\(\\hat{y}_i\\) = predicted values from model"
  },
  {
    "objectID": "slides/03-slides.html#what-is-a-residual",
    "href": "slides/03-slides.html#what-is-a-residual",
    "title": "Linear Regression Fundamentals",
    "section": "What is a Residual?",
    "text": "What is a Residual?\n\nDefinition: A residual is the difference between an observed value and its predicted value from the model\n\n\nFormula:\n\\[\\hat\\varepsilon_i = y_i-\\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slides.html#you-try-calculating-residuals",
    "href": "slides/03-slides.html#you-try-calculating-residuals",
    "title": "Linear Regression Fundamentals",
    "section": "You Try: Calculating Residuals",
    "text": "You Try: Calculating Residuals\n\nProblem: Given the regression equation \\(\\hat{y} = 2.3 + 1.5x\\) and the data points below, calculate the residual for each observation:\n\n\n\nx\ny\n\\(\\hat{y}\\)\n\\(\\hat{\\varepsilon}\\)\n\n\n\n\n1\n4.2\n?\n?\n\n\n3\n6.8\n?\n?\n\n\n5\n11.1\n?\n?\n\n\n\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/03-slides.html#lets-try-it-in-r",
    "href": "slides/03-slides.html#lets-try-it-in-r",
    "title": "Linear Regression Fundamentals",
    "section": "Let‚Äôs Try It in R",
    "text": "Let‚Äôs Try It in R\nProblem: Given the same regression equation \\(\\hat{y} = 2.3 + 1.5x\\) and \\(y = [4.2, 6.8, 11.1]\\), \\(x = [1, 3, 5]\\):\n\nPut the x values in a design matrix called X and the outcome in a vector called y\nPut the coefficients in a vector called beta\n\nMultiply them to get \\(\\hat{y}\\)\nSubtract from y to get residuals\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/03-slides.html#lets-try-it-in-r-solution",
    "href": "slides/03-slides.html#lets-try-it-in-r-solution",
    "title": "Linear Regression Fundamentals",
    "section": "Let‚Äôs Try It in R Solution",
    "text": "Let‚Äôs Try It in R Solution\n\n\n# 1. Create design matrix X\nX &lt;- matrix(c(1, 1, \n              1, 3, \n              1, 5),\n            byrow = TRUE, ncol = 2)\n# Create y\ny &lt;- c(4.2, 6.8, 11.1)\n\n# 2. Create beta vector\nbeta &lt;- c(2.3, 1.5)\n\n# 3. Calculate y_hat\ny_hat &lt;- X %*% beta\n\n# 4. Calculate residuals\nresiduals &lt;- y - y_hat\n\nresiduals\n\n\n     [,1]\n[1,]  0.4\n[2,]  0.0\n[3,]  1.3"
  },
  {
    "objectID": "slides/03-slides.html#the-goal-minimize-squared-errors",
    "href": "slides/03-slides.html#the-goal-minimize-squared-errors",
    "title": "Linear Regression Fundamentals",
    "section": "The Goal: Minimize Squared Errors",
    "text": "The Goal: Minimize Squared Errors\n\nSum of squared errors:\n\\[\\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n \\hat\\varepsilon_i^2\\]\n\n\n\\[\\text{SSE} = (\\mathbf{y}- \\mathbf{X}\\boldsymbol\\beta)^T(\\mathbf{y}- \\mathbf{X}\\boldsymbol\\beta)\\]"
  },
  {
    "objectID": "slides/03-slides.html#you-try",
    "href": "slides/03-slides.html#you-try",
    "title": "Linear Regression Fundamentals",
    "section": "You Try",
    "text": "You Try\n\nProblem: Verify that these two expressions for SSE are the same:\nIndividual terms: \\[\\text{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\]\nMatrix form: \\[\\text{SSE} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]\nTask: Expand the matrix form and show it equals the summation form"
  },
  {
    "objectID": "slides/03-slides.html#visualizing-squared-residuals",
    "href": "slides/03-slides.html#visualizing-squared-residuals",
    "title": "Linear Regression Fundamentals",
    "section": " Visualizing Squared Residuals",
    "text": "Visualizing Squared Residuals"
  },
  {
    "objectID": "slides/03-slides.html#visualizing-squared-residuals-1",
    "href": "slides/03-slides.html#visualizing-squared-residuals-1",
    "title": "Linear Regression Fundamentals",
    "section": " Visualizing Squared Residuals",
    "text": "Visualizing Squared Residuals"
  },
  {
    "objectID": "slides/03-slides.html#application-exercise",
    "href": "slides/03-slides.html#application-exercise",
    "title": "Linear Regression Fundamentals",
    "section": " Application Exercise",
    "text": "Application Exercise\n\nGo to lucy.shinyapps.io/least-squares/.\nThis shows a scatter plot of 10 data points with a line estimating the relationship between x and y. Drag the blue points to change the line.\n\nSee if you can find a line that minimizes the sum of square errors\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/03-slides.html#what-were-really-doing",
    "href": "slides/03-slides.html#what-were-really-doing",
    "title": "Linear Regression Fundamentals",
    "section": "What We‚Äôre Really Doing",
    "text": "What We‚Äôre Really Doing\n\nThe regression equation: \\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\]\n\n\nThe goal: Find \\(\\boldsymbol{\\beta}\\) that makes \\(\\mathbf{X}\\boldsymbol{\\beta}\\) as close as possible to \\(\\mathbf{y}\\)"
  },
  {
    "objectID": "slides/03-slides.html#understanding-the-vector-space",
    "href": "slides/03-slides.html#understanding-the-vector-space",
    "title": "Linear Regression Fundamentals",
    "section": "Understanding the Vector Space",
    "text": "Understanding the Vector Space\n\nIf we have \\(n\\) observations, we work in \\(n\\)-dimensional space\n\n\n\\(\\mathbf{y}\\) is a vector with \\(n\\) components (one value per observation)\n\n\n\\(\\mathbf{X}\\boldsymbol{\\beta}\\) is also a vector with \\(n\\) components (one prediction per observation)\n\n\nBoth vectors live in the same \\(n\\)-dimensional space"
  },
  {
    "objectID": "slides/03-slides.html#what-is-column-space",
    "href": "slides/03-slides.html#what-is-column-space",
    "title": "Linear Regression Fundamentals",
    "section": "What is Column Space?",
    "text": "What is Column Space?\n\nIn words: All possible predictions your model can make\n\n\nThink of it as: Every combination of your predictor variables"
  },
  {
    "objectID": "slides/03-slides.html#column-space-with-numbers",
    "href": "slides/03-slides.html#column-space-with-numbers",
    "title": "Linear Regression Fundamentals",
    "section": "Column Space with Numbers",
    "text": "Column Space with Numbers\n\nYour data: \\(x = [1, 2, 3]\\) with 3 observations\n\n\nDesign matrix: \\(\\mathbf{X} = \\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\\\ 1 & 3 \\end{bmatrix}\\)\n\n\nColumn space contains: All vectors of the form \\(\\beta_0 \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} + \\beta_1 \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/03-slides.html#examples-of-vectors-in-column-space",
    "href": "slides/03-slides.html#examples-of-vectors-in-column-space",
    "title": "Linear Regression Fundamentals",
    "section": "Examples of Vectors in Column Space",
    "text": "Examples of Vectors in Column Space\n\nExample 1: Choose \\(\\beta_0=0, \\beta_1=2\\) gives \\([2, 4, 6]\\)\n\n\nIn words: Intercept = 0, slope = 2, so predictions are [2, 4, 6]\n\n\nExample 2: Choose \\(\\beta_0=5, \\beta_1=0\\) gives \\([5, 5, 5]\\)\n\n\nIn words: Intercept = 5, slope = 0, so all predictions equal 5"
  },
  {
    "objectID": "slides/03-slides.html#the-fundamental-problem",
    "href": "slides/03-slides.html#the-fundamental-problem",
    "title": "Linear Regression Fundamentals",
    "section": "The Fundamental Problem",
    "text": "The Fundamental Problem\n\nYour actual observed data: \\(\\mathbf{y} = [2.1, 3.9, 5.8]\\)\n\n\nQuestion: Is there some \\(\\beta_0, \\beta_1\\) such that \\(\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{y}\\) exactly?\n\n\nIn other words: Is \\([2.1, 3.9, 5.8]\\) exactly equal to \\(\\beta_0[1,1,1] + \\beta_1[1,2,3]\\)?"
  },
  {
    "objectID": "slides/03-slides.html#why-we-usually-cant-hit-exactly",
    "href": "slides/03-slides.html#why-we-usually-cant-hit-exactly",
    "title": "Linear Regression Fundamentals",
    "section": "Why We Usually Can‚Äôt Hit Exactly",
    "text": "Why We Usually Can‚Äôt Hit Exactly\n\nAnswer: Usually no! Real data has irreducible error\n\nYour observed \\(\\mathbf{y}\\) typically doesn‚Äôt lie perfectly in the column space*\n\nIn words: Your data points don‚Äôt lie exactly on any straight line"
  },
  {
    "objectID": "slides/03-slides.html#the-geometric-solution",
    "href": "slides/03-slides.html#the-geometric-solution",
    "title": "Linear Regression Fundamentals",
    "section": "The Geometric Solution",
    "text": "The Geometric Solution\n\nSince we can‚Äôt hit \\(\\mathbf{y}\\) exactly, let‚Äôs get as close as possible\nFind the point in the column space that is closest to \\(\\mathbf{y}\\)\n\nThis closest point is the orthogonal projection of \\(\\mathbf{y}\\) onto the column space"
  },
  {
    "objectID": "slides/03-slides.html#the-residual-vector",
    "href": "slides/03-slides.html#the-residual-vector",
    "title": "Linear Regression Fundamentals",
    "section": "The Residual Vector",
    "text": "The Residual Vector\n\nDefinition: \\(\\hat\\varepsilon = \\mathbf{y} - \\hat{\\mathbf{y}}\\)\n\nIn words: The difference between what we observed and what we predicted\n\nThis represents the part of \\(\\mathbf{y}\\) we cannot explain with our model"
  },
  {
    "objectID": "slides/03-slides.html#key-geometric-property",
    "href": "slides/03-slides.html#key-geometric-property",
    "title": "Linear Regression Fundamentals",
    "section": "Key Geometric Property",
    "text": "Key Geometric Property\n\nThe residual vector is perpendicular to the column space\nMathematical notation: \\(\\hat\\varepsilon \\perp \\text{Col}(\\mathbf{X})\\)\n\nWhy this matters: Perpendicularity guarantees we found the closest point"
  },
  {
    "objectID": "slides/03-slides.html#why-perpendicular-means-closest",
    "href": "slides/03-slides.html#why-perpendicular-means-closest",
    "title": "Linear Regression Fundamentals",
    "section": "Why Perpendicular Means Closest?",
    "text": "Why Perpendicular Means Closest?\n\nImagine dropping a ball onto a table from above\n\nThe shortest path is straight down (perpendicular to the table)\n\nAny diagonal path would be longer\n\nThe same principle applies in higher dimensions"
  },
  {
    "objectID": "slides/03-slides.html#from-geometry-to-algebra",
    "href": "slides/03-slides.html#from-geometry-to-algebra",
    "title": "Linear Regression Fundamentals",
    "section": "From Geometry to Algebra",
    "text": "From Geometry to Algebra\n\nGeometric fact: \\(\\hat\\varepsilon \\perp \\text{Col}(\\mathbf{X})\\)\n\nThis means \\(\\hat\\varepsilon\\) is perpendicular to every vector in the column space\n\nSince columns of \\(\\mathbf{X}\\) span the column space, \\(\\hat\\varepsilon\\) is perpendicular to each column"
  },
  {
    "objectID": "slides/03-slides.html#mathematical-expression-of-perpendicularity",
    "href": "slides/03-slides.html#mathematical-expression-of-perpendicularity",
    "title": "Linear Regression Fundamentals",
    "section": "Mathematical Expression of Perpendicularity",
    "text": "Mathematical Expression of Perpendicularity\n\nIf \\(\\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_p]\\), then:\n\n\n\\(\\mathbf{x}_1^T\\hat\\varepsilon = 0\\), \\(\\mathbf{x}_2^T\\hat\\varepsilon = 0\\), ‚Ä¶, \\(\\mathbf{x}_p^T\\hat\\varepsilon = 0\\)\n\n\nStacking these equations gives us: \\(\\mathbf{X}^T\\hat\\varepsilon = \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/03-slides.html#the-normal-equations",
    "href": "slides/03-slides.html#the-normal-equations",
    "title": "Linear Regression Fundamentals",
    "section": "The Normal Equations",
    "text": "The Normal Equations\n\nStarting from: \\(\\mathbf{X}^T\\hat\\varepsilon = \\mathbf{0}\\)\n\n\nSubstitute \\(\\hat\\varepsilon = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\):\n\\[\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\]\n\n\nIn words: ‚ÄúThe residuals are perpendicular to every column of \\(\\mathbf{X}\\)‚Äù"
  },
  {
    "objectID": "slides/03-slides.html#you-try-matrix-algebra",
    "href": "slides/03-slides.html#you-try-matrix-algebra",
    "title": "Linear Regression Fundamentals",
    "section": "You Try: Matrix Algebra",
    "text": "You Try: Matrix Algebra\n\nStarting with: \\(\\mathbf{A}\\mathbf{x} + \\mathbf{b} = \\mathbf{c}\\)\nSolve for \\(\\mathbf{x}\\) step by step:\n\nFirst, isolate the \\(\\mathbf{A}\\mathbf{x}\\) term\n\nThen multiply both sides by \\(\\mathbf{A}^{-1}\\) (on the left!)\n\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/03-slides.html#expanding-the-normal-equations",
    "href": "slides/03-slides.html#expanding-the-normal-equations",
    "title": "Linear Regression Fundamentals",
    "section": "Expanding the Normal Equations",
    "text": "Expanding the Normal Equations\n\nStart with: \\(\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nDistribute: \\(\\mathbf{X}^T\\mathbf{y} - \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{0}\\)\n\n\nMove the second term to the right side: \\(\\mathbf{X}^T\\mathbf{y} = \\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\)"
  },
  {
    "objectID": "slides/03-slides.html#solving-for-beta",
    "href": "slides/03-slides.html#solving-for-beta",
    "title": "Linear Regression Fundamentals",
    "section": "Solving for Beta",
    "text": "Solving for Beta\n\nWe have: \\(\\mathbf{X}^T\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^T\\mathbf{y}\\)\n\n\nTo solve for \\(\\hat{\\boldsymbol{\\beta}}\\), multiply both sides by \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\):\n\n\nResult: \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\\)\n\n\nThis is the least squares solution!"
  },
  {
    "objectID": "slides/03-slides.html#the-hat-matrix",
    "href": "slides/03-slides.html#the-hat-matrix",
    "title": "Linear Regression Fundamentals",
    "section": "The Hat Matrix",
    "text": "The Hat Matrix\n\nDefinition: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\n\n\nWhat it does: \\(\\hat{\\mathbf{y}} = \\mathbf{H}\\mathbf{y}\\)\n\n\nIn words: Takes your observed data and produces the closest possible predictions\n\n\nNickname: ‚ÄúPuts the hat on \\(\\mathbf{y}\\)‚Äù to get \\(\\hat{\\mathbf{y}}\\)"
  },
  {
    "objectID": "slides/03-slides.html#hat-matrix-properties",
    "href": "slides/03-slides.html#hat-matrix-properties",
    "title": "Linear Regression Fundamentals",
    "section": "Hat Matrix Properties",
    "text": "Hat Matrix Properties\n\nSymmetric: \\(\\mathbf{H}^T = \\mathbf{H}\\)\n\n\nIdempotent: \\(\\mathbf{H}^2 = \\mathbf{H}\\)"
  },
  {
    "objectID": "slides/03-slides.html#you-try-hat-matrix-property",
    "href": "slides/03-slides.html#you-try-hat-matrix-property",
    "title": "Linear Regression Fundamentals",
    "section": "You Try: Hat Matrix Property",
    "text": "You Try: Hat Matrix Property\n\nVerify that: \\(\\mathbf{H}^2 = \\mathbf{H}\\)\nHint: Substitute the definition \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\) and multiply it out\nRemember: \\((\\mathbf{A}^{-1})^{-1} = \\mathbf{A}\\)\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/03-slides.html#why-least-squares",
    "href": "slides/03-slides.html#why-least-squares",
    "title": "Linear Regression Fundamentals",
    "section": "Why ‚ÄúLeast Squares‚Äù?",
    "text": "Why ‚ÄúLeast Squares‚Äù?\n\nWe minimize: \\(\\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\)\n\n\nIn words: Sum of squared differences between observed and predicted\n\n\nThis equals: \\(||\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}||^2\\)\n\n\nIn words: Squared distance between the observed vector and prediction vector"
  },
  {
    "objectID": "slides/03-slides.html#key-geometric-insights",
    "href": "slides/03-slides.html#key-geometric-insights",
    "title": "Linear Regression Fundamentals",
    "section": "Key Geometric Insights",
    "text": "Key Geometric Insights\n\n1. Regression is projection: Finding the closest point in the column space to \\(\\mathbf{y}\\)\n\n\n2. Orthogonality is key: Residuals perpendicular to column space guarantees minimum distance\n\n\n3. Hat matrix is the projection operator: \\(\\mathbf{H}\\) projects onto column space"
  },
  {
    "objectID": "slides/03-slides.html#you-try-1",
    "href": "slides/03-slides.html#you-try-1",
    "title": "Linear Regression Fundamentals",
    "section": " You Try",
    "text": "You Try\n\nTry this in R:\n1. x &lt;- 1:10; y &lt;- 2*x + rnorm(10)\n2. X &lt;- cbind(1, x) # Design matrix\n3. H &lt;- X %*% solve(crossprod(X)) %*% t(X) # Hat matrix\n4. Check: all.equal(H %*% H, H) # Verify idempotent\n5. e &lt;- y - H %*% y # Residuals\n6. Check: t(X) %*% e # Should be approximately zero\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/01-slides.html#section",
    "href": "slides/01-slides.html#section",
    "title": "Welcome to Linear Models",
    "section": "",
    "text": "‚Äútruth ‚Ä¶ is much too complicated to allow anything but approximations‚Äù\n- John von Neumann\n\n\n\n\nJohn von Neumann, wearer of funny hats via https://farkasdilemma.wordpress.com/2013/01/04/john-von-neumannm-wearer-of-funny-hats/"
  },
  {
    "objectID": "slides/01-slides.html#section-1",
    "href": "slides/01-slides.html#section-1",
    "title": "Welcome to Linear Models",
    "section": "",
    "text": "‚ÄúAll models are wrong, but some are useful‚Äù\n- George Box\n\n\n   \n\nDavidMCEddy at en.wikipedia  CC BY-SA 3.0 , via Wikimedia Commons"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model",
    "href": "slides/01-slides.html#is-this-a-linear-model",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?"
  },
  {
    "objectID": "slides/01-slides.html#what-is-the-equation",
    "href": "slides/01-slides.html#what-is-the-equation",
    "title": "Welcome to Linear Models",
    "section": "What is the equation?",
    "text": "What is the equation?\n\n\\[y = \\beta_0 + \\beta_1 x + \\varepsilon\\]"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-1",
    "href": "slides/01-slides.html#is-this-a-linear-model-1",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?\n\n\n Where is \\(\\beta_0\\)"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-2",
    "href": "slides/01-slides.html#is-this-a-linear-model-2",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?\n\n\n Where is \\(\\beta_0\\)"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-3",
    "href": "slides/01-slides.html#is-this-a-linear-model-3",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?\n\n\n Where is \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-4",
    "href": "slides/01-slides.html#is-this-a-linear-model-4",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?\n\n\n Where is \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/01-slides.html#what-is-the-equation-1",
    "href": "slides/01-slides.html#what-is-the-equation-1",
    "title": "Welcome to Linear Models",
    "section": "What is the equation?",
    "text": "What is the equation?\n\n\\[y = \\beta_0 + \\beta_1 x + \\varepsilon\\]"
  },
  {
    "objectID": "slides/01-slides.html#what-is-the-equation-2",
    "href": "slides/01-slides.html#what-is-the-equation-2",
    "title": "Welcome to Linear Models",
    "section": "What is the equation?",
    "text": "What is the equation?\n\n\\[\nX = \\begin{bmatrix}1 & x_1\\\\\n\\vdots & \\vdots \\\\ 1 & x_n\\end{bmatrix},\\quad\n\\beta = \\begin{bmatrix}\\beta_0\\\\ \\beta_1\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/01-slides.html#what-does-the-data-look-like",
    "href": "slides/01-slides.html#what-does-the-data-look-like",
    "title": "Welcome to Linear Models",
    "section": "What does the ‚Äúdata‚Äù look like?",
    "text": "What does the ‚Äúdata‚Äù look like?\n\n\n\n  (Intercept)        x\n1           1 1.920595\n2           1 3.093363\n3           1 5.301387\n4           1 8.990286\n5           1 1.218501\n6           1 8.882287"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-5",
    "href": "slides/01-slides.html#is-this-a-linear-model-5",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?"
  },
  {
    "objectID": "slides/01-slides.html#what-is-the-equation-3",
    "href": "slides/01-slides.html#what-is-the-equation-3",
    "title": "Welcome to Linear Models",
    "section": "What is the equation?",
    "text": "What is the equation?\n\\[y = \\beta_0 + \\sum_{j=1}^{J} \\beta_j B_j(x) + \\varepsilon\\]\n\nwhere \\(B_j(x)\\) are known spline basis functions\nthe model is linear in the \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/01-slides.html#what-does-the-data-look-like-1",
    "href": "slides/01-slides.html#what-does-the-data-look-like-1",
    "title": "Welcome to Linear Models",
    "section": "What does the ‚Äúdata‚Äù look like?",
    "text": "What does the ‚Äúdata‚Äù look like?\n\n\n\n  (Intercept) ns(x, df = 3)1 ns(x, df = 3)2 ns(x, df = 3)3\n1           1   -0.095842465      0.4743374     -0.3103069\n2           1    0.006273703      0.5498909     -0.3597333\n3           1    0.444366108      0.4236598     -0.2337245\n4           1    0.133806217      0.3714757      0.4916902\n5           1   -0.103895176      0.3825795     -0.2502798\n6           1    0.164715184      0.3660870      0.4649746"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-6",
    "href": "slides/01-slides.html#is-this-a-linear-model-6",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?"
  },
  {
    "objectID": "slides/01-slides.html#is-this-a-linear-model-7",
    "href": "slides/01-slides.html#is-this-a-linear-model-7",
    "title": "Welcome to Linear Models",
    "section": "Is this a linear model?",
    "text": "Is this a linear model?"
  },
  {
    "objectID": "slides/01-slides.html#what-is-the-equation-4",
    "href": "slides/01-slides.html#what-is-the-equation-4",
    "title": "Welcome to Linear Models",
    "section": "What is the equation?",
    "text": "What is the equation?\n\\[y = \\sum_{k=1}^{K} \\beta_k \\, \\mathbf{1}\\{x \\in R_k\\} + \\varepsilon\\]\n\nwhere \\(R_1,\\ldots,R_K\\) are each of the regions\nthis is linear in the parameters \\(\\beta_k\\)"
  },
  {
    "objectID": "slides/01-slides.html#what-does-the-data-look-like-2",
    "href": "slides/01-slides.html#what-does-the-data-look-like-2",
    "title": "Welcome to Linear Models",
    "section": "What does the ‚Äúdata‚Äù look like?",
    "text": "What does the ‚Äúdata‚Äù look like?\n\n\n\n  ind1 ind2 ind3 ind4 ind5 ind6 ind7 ind8\n1    0    0    0    0    0    0    0    1\n2    0    0    0    0    0    0    1    0\n3    0    0    0    0    0    0    1    0\n4    0    0    0    0    0    0    0    1\n5    0    1    0    0    0    0    0    0\n6    0    0    1    0    0    0    0    0"
  },
  {
    "objectID": "rstudio-pro.html",
    "href": "rstudio-pro.html",
    "title": "Logging into RStudio Pro",
    "section": "",
    "text": "Follow these steps to access RStudio Pro:\n\nMake sure you are connected to the WFU Network. This means you must be on the eduroam wireless network, or connected through the VPN if you are off-campus.\n\nIf you are off-campus, go through the VPN first: WFU VPN Instructions.\n\nGo to login.deac.wfu.edu and sign in with your school email and password.\nOnce logged in, click the RStudio icon.\nSet your working directory to /deac/sta/classes/sta312/YOUR-USERNAME where YOUR-USERNAME is replaced by the first part of your email address, i.e., mine is mcgowald because my email is mcgowald@wfu.edu\nSet the number of hours to how long you plan to work on the project (I usually enter 4).\nClick Launch.\nThe session will show as Queued for a moment. Once it is ready, the status will turn green and say Ready.\nClick the Connect to RStudio Server button. You should now be in RStudio Pro.\n\n\nNote: You are not required to use this setup (i.e., you can download RStudio and all the necessary packages locally). However, the focus of this class is not on technical setup, so we will not be able to spend time troubleshooting issues if you are not using the official setup described here.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Using the RStudio Pro Server"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 312: Linear Models",
    "section": "",
    "text": "Course Info\nLocation: Carswell 208\nTime: W/F 9:30a-10:45a\n\n\n Office Hours\nInstructor: Dr.¬†Lucy D‚ÄôAgostino McGowan\nEmail: mcgowald@wfu.edu\nHours: Bookable\nOffice: Manchester 342\nMath & Stats Center: mathandstatscenter@wfu.edu\nLocation: Math & Stats Center\n\n\n\n Texts\nThe main text book is: Linear Models with R by Julian Faraway\n\n\n Materials\nThis class is very hands on; be sure to bring a fully charged laptop to every class."
  },
  {
    "objectID": "help-quarto.html",
    "href": "help-quarto.html",
    "title": "Creating a New Quarto Document in RStudio",
    "section": "",
    "text": "To create a new Quarto document:\n\nBe sure that you are in the correct project for the exercise or assignment. If you need help creating a new project here are some tips.\nIn RStudio, go to the menu bar and select File &gt; New File &gt; Quarto Document.\nEnter a title for your document and select the output format (e.g., HTML, PDF, Word).\nClick Create. A new Quarto file (.qmd) will open.\nSave the file to your project directory\nUse the toolbar or the Render button to build your document.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Creating a Quarto Document"
    ]
  },
  {
    "objectID": "ex/ex-3.html",
    "href": "ex/ex-3.html",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "",
    "text": "This problem set covers the fundamental concepts of linear regression, including matrix formulations, geometric interpretations, and computational methods. Show all work and provide clear explanations for your reasoning.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#instructions",
    "href": "ex/ex-3.html#instructions",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "",
    "text": "This problem set covers the fundamental concepts of linear regression, including matrix formulations, geometric interpretations, and computational methods. Show all work and provide clear explanations for your reasoning.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-1",
    "href": "ex/ex-3.html#problem-1",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 1",
    "text": "Problem 1\nConsider the following dataset with two predictors:\n\n\nObservation\nx1\nx2\ny\n\n\n\n1\n2\n1\n5.2\n\n\n2\n3\n4\n8.1\n\n\n3\n1\n2\n4.8\n\n\n4\n4\n3\n9.5\n\n\n\na) Write out the design matrix X for the multiple regression model with intercept term.\nb) Calculate \\(\\mathbf{X}^T\\mathbf{X}\\) and \\(\\mathbf{X}^T\\mathbf{y}\\) by hand. Show your matrix multiplication steps.\nc) Using your results from Part B, set up the normal equations \\(\\mathbf{X}^T\\mathbf{X}\\hat\\beta=\\mathbf{X}^T\\mathbf{y}\\) and solve for the coefficient vector \\(\\hat\\beta\\). (You can use R if you need to take an inverse).\nd) Verify your answer using R‚Äôs built-in functions.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-2",
    "href": "ex/ex-3.html#problem-2",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 2",
    "text": "Problem 2\nUsing the data from Problem 1 and your estimated coefficients:\na) Calculate the predicted values \\(\\hat{y}_i\\) for each observation by hand.\nb) Calculate the residuals \\(\\hat\\varepsilon=y_i-\\hat{y}_i\\) for each observation.\nc) Compute the sum of squared errors (SSE) using both formulations:\n\nIndividual terms: SSE \\(= \\sum(y_i - \\hat{y}_i)^2\\)\n\nMatrix form: SSE \\(=  (\\mathbf{y}-\\mathbf{X}\\hat\\beta)^T(\\mathbf{y}-\\mathbf{X}\\hat\\beta)\\)\n\n\nd) Verify that your residuals sum to approximately zero and explain why this should be true geometrically.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-3",
    "href": "ex/ex-3.html#problem-3",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 3",
    "text": "Problem 3\na) For simple linear regression with n = 3 observations and design matrix:\n\\[\\mathbf{X} = \\begin{bmatrix}1 & 2\\\\1 & 4\\\\1&6\\end{bmatrix}\\]\nCalculate the hat matrix (\\(\\mathbf{H}\\)) by hand (you can use R if you need to take an inverse).\nb) Verify that \\(\\mathbf{H}\\) is idempotent.\nc) Show that \\(\\mathbf{H}\\) is symmetric and interpret what this property means geometrically.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-4",
    "href": "ex/ex-3.html#problem-4",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 4",
    "text": "Problem 4\nConsider the simple linear regression case with the design matrix from Problem 3.\na) Write out two specific vectors that lie in the column space of \\(\\mathbf{X}\\). Explain what these vectors represent in terms of the regression model.\nb) If the observed response vector is \\(\\mathbf{y} = \\begin{bmatrix}3\\\\7\\\\12\\end{bmatrix}\\), explain why this vector likely does NOT lie exactly in the column space of \\(\\mathbf{X}\\). What does this mean practically?\nc) Calculate the projection of \\(\\mathbf{y}\\) onto the column space (i.e., \\(\\mathbf{\\hat{y}} = \\mathbf{Hy}\\)) and show that the residual vector is orthogonal to the column space by verifying \\(\\mathbf{X}^T\\hat\\varepsilon=0\\).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-5",
    "href": "ex/ex-3.html#problem-5",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 5",
    "text": "Problem 5\na) Starting from the geometric principle that residuals must be orthogonal to the column space of \\(\\mathbf{X}\\), derive the normal equations step by step. Begin with the condition \\(\\mathbf{X}^T\\hat\\varepsilon = 0\\) and show all algebraic steps to arrive at \\(\\mathbf{X}^T\\mathbf{X}\\hat\\beta=\\mathbf{X}^T\\mathbf{y}\\).\nb) Explain why we multiply both sides by \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\) to solve for \\(\\hat\\beta\\), and under what conditions this inverse might not exist.\nc) Show that the least squares estimator \\(\\hat\\beta = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\\) minimizes the sum of squared errors by demonstrating that this solution satisfies the orthogonality condition.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-3.html#problem-6",
    "href": "ex/ex-3.html#problem-6",
    "title": "Linear Regression Fundamentals Problem Set",
    "section": "Problem 6",
    "text": "Problem 6\nYou are given the following dataset with 10 observations:\n\n\nx\ny\n\n\n\n1\n4.8\n\n\n2\n6.2\n\n\n3\n8.1\n\n\n4\n9.9\n\n\n5\n11.5\n\n\n6\n13.8\n\n\n7\n15.2\n\n\n8\n17.1\n\n\n9\n18.9\n\n\n10\n21.3\n\n\n\na) Implement the least squares solution in R using matrix operations. Calculate \\(\\hat\\beta\\) without using lm().\nb) Compare your results with R‚Äôs lm() function and verify they match.\nc) Using the grid below, hand-draw the following elements:\n\nPlot the 10 data points from the table above\n\nDraw the true regression line: y = 3.5 + 1.8x (shown as a dashed line)\nDraw your fitted regression line from Part A (shown as a solid line)\nLabel both lines clearly in your plot\n\n\n\n\n\n\n\n\n\n(You don‚Äôt have to upload this drawing on Canvas, but make sure you do it and understand it, we will do it during the board work portion in class.)\nd) Based on your plot, comment on how well the fitted line approximates the true relationship. What does this tell you about the effectiveness of least squares estimation?",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 3: Linear Regression Fundamentals"
    ]
  },
  {
    "objectID": "ex/ex-1.html",
    "href": "ex/ex-1.html",
    "title": "Exercise 1",
    "section": "",
    "text": "Exercise 1: Login to RStudio Pro\n\nGo to course website ‚Üí Computing ‚Üí Using the RStudio Server\nFollow login instructions\nLog in with your credentials\n\nCheck: You should see the RStudio interface with 4 panes.\nExercise 2: Create RStudio Project\n\nFile ‚Üí New Project ‚Üí New Directory ‚Üí New Project\nName: ex-1\n\nClick Create Project\n\nCheck: Project name appears in top-right corner.\nExercise 3: Create Quarto Document\n\nFile ‚Üí New File ‚Üí Quarto Document\nTitle: ‚ÄúMy First Analysis‚Äù\nSave as analysis.qmd\n\n\nCheck: New .qmd file is open and saved.\nExercise 4: Install faraway Package and Load Data\nRun this code in the console ONCE:\n\ninstall.packages(\"faraway\")\n\nThen run this:\n\nlibrary(faraway)\nlibrary(ggplot2)\n\n# Test it works\ndata(teengamb)\nhead(teengamb)\n\n  sex status income verbal gamble\n1   1     51   2.00      8    0.0\n2   1     28   2.50      8    0.0\n3   1     37   2.00      6    0.0\n4   1     28   7.00      4    7.3\n5   1     65   2.00      8   19.6\n6   1     61   3.47      6    0.1\n\n\nCheck: You see the teengamb dataset.\nNow run this in the console:\n\n?teengamb\n\nQuestion: What is in this dataset?\nAction: Add the code below to your .qmd file along with a short description of the data.\n\nlibrary(faraway)\nlibrary(ggplot2)\ndata(teengamb)\n\nExercise 5: Linear Model and Plot\nAdd the following code to your .qmd file. Try running it.\n\n# Fit linear model\nmodel1 &lt;- lm(gamble ~ income, data = teengamb)\nsummary(model1)\n\n\nCall:\nlm(formula = gamble ~ income, data = teengamb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.020 -11.874  -3.757  11.934 107.120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   -6.325      6.030  -1.049      0.3    \nincome         5.520      1.036   5.330 3.05e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 24.95 on 45 degrees of freedom\nMultiple R-squared:  0.387, Adjusted R-squared:  0.3734 \nF-statistic: 28.41 on 1 and 45 DF,  p-value: 3.045e-06\n\n# Create plot\nggplot(teengamb, aes(x = income, y = gamble)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = \"y ~ x\") +\n  labs(title = \"Income vs Gambling\",\n       x = \"Income\", \n       y = \"Gambling\")\n\n\n\n\n\n\n\nCheck: You have model output and a scatter plot with trend line.\nFinish\nClick ‚ÄúRender‚Äù to create your HTML report. Upload your .html file in Canvas under Exercise 1",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 1"
    ]
  },
  {
    "objectID": "demo/hat-matrix-symmetry.html",
    "href": "demo/hat-matrix-symmetry.html",
    "title": "Hat Matrix Symmetry Visualization",
    "section": "",
    "text": "Point 1 X:  1.0\n\n\nPoint 2 X:  2.0\n\n\nPoint 3 X:  -1.0\n\n\nRandomize Points",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Hat Matrix Symmetry"
    ]
  },
  {
    "objectID": "demo/hat-matrix-symmetry.html#interactive-linear-regression-example",
    "href": "demo/hat-matrix-symmetry.html#interactive-linear-regression-example",
    "title": "Hat Matrix Symmetry Visualization",
    "section": "",
    "text": "Point 1 X:  1.0\n\n\nPoint 2 X:  2.0\n\n\nPoint 3 X:  -1.0\n\n\nRandomize Points",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Hat Matrix Symmetry"
    ]
  },
  {
    "objectID": "demo/hat-matrix-symmetry.html#hat-matrix-h",
    "href": "demo/hat-matrix-symmetry.html#hat-matrix-h",
    "title": "Hat Matrix Symmetry Visualization",
    "section": "Hat Matrix H",
    "text": "Hat Matrix H",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Hat Matrix Symmetry"
    ]
  },
  {
    "objectID": "demo/hat-matrix-symmetry.html#what-symmetry-means",
    "href": "demo/hat-matrix-symmetry.html#what-symmetry-means",
    "title": "Hat Matrix Symmetry Visualization",
    "section": "What Symmetry Means:",
    "text": "What Symmetry Means:\nHij = Hji means:\n\nHow much point i influences point j‚Äôs fitted value = How much point j influences point i‚Äôs fitted value\n\nThis reciprocal relationship holds for ALL pairs of points\nReciprocal influence is a geometric consequence of orthogonal projection",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Hat Matrix Symmetry"
    ]
  },
  {
    "objectID": "demo/hat-matrix-symmetry.html#key-observations",
    "href": "demo/hat-matrix-symmetry.html#key-observations",
    "title": "Hat Matrix Symmetry Visualization",
    "section": "Key Observations",
    "text": "Key Observations",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Hat Matrix Symmetry"
    ]
  },
  {
    "objectID": "demo/least-squares.html",
    "href": "demo/least-squares.html",
    "title": "Interactive Least Squares Visualization",
    "section": "",
    "text": "Adjust the red line using the sliders below to try to minimize the sum of squared errors. The blue squares show the squared residuals!\n\n\nIntercept \\(\\hat\\beta_0\\)\n\n1.5\n\n\nSlope \\(\\hat\\beta_1\\)\n\n1\n\n\nShow Optimal\n\n\n\n\n\n\nYour Line\ny = 1.50 + 1.00x\n\n\nOptimal Least Squares\ny = 1.50 + 1.00x\n\n\n\n\nYour SSE\n0.00\n\n\nOptimal SSE\n0.00",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Least Squares Solution"
    ]
  },
  {
    "objectID": "demo/least-squares.html#interactive-least-squares-learning-tool",
    "href": "demo/least-squares.html#interactive-least-squares-learning-tool",
    "title": "Interactive Least Squares Visualization",
    "section": "",
    "text": "Adjust the red line using the sliders below to try to minimize the sum of squared errors. The blue squares show the squared residuals!\n\n\nIntercept \\(\\hat\\beta_0\\)\n\n1.5\n\n\nSlope \\(\\hat\\beta_1\\)\n\n1\n\n\nShow Optimal\n\n\n\n\n\n\nYour Line\ny = 1.50 + 1.00x\n\n\nOptimal Least Squares\ny = 1.50 + 1.00x\n\n\n\n\nYour SSE\n0.00\n\n\nOptimal SSE\n0.00",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Least Squares Solution"
    ]
  },
  {
    "objectID": "demo/least-squares.html#key-concepts",
    "href": "demo/least-squares.html#key-concepts",
    "title": "Interactive Least Squares Visualization",
    "section": "Key Concepts",
    "text": "Key Concepts\nGoal: Find the line \\(\\hat{y} = \\hat\\beta_0 + \\hat\\beta_1x\\) that minimizes the Sum of Squared Errors (SSE)\nThe blue squares show the squared residuals - their total area equals the SSE!\nWhat to Try:\n\nAdjust the sliders to minimize the total area of blue squares\n\nTry to match the optimal (green) line\n\nNotice how the squares get smaller as you approach the optimal solution",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Demos",
      "Least Squares Solution"
    ]
  },
  {
    "objectID": "ex/ex-2.html",
    "href": "ex/ex-2.html",
    "title": "Matrix Problem Set",
    "section": "",
    "text": "Complete all problems showing your work. For matrix calculations, show each step clearly. You may use R to verify your answers, but show the mathematical steps first.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#instructions",
    "href": "ex/ex-2.html#instructions",
    "title": "Matrix Problem Set",
    "section": "",
    "text": "Complete all problems showing your work. For matrix calculations, show each step clearly. You may use R to verify your answers, but show the mathematical steps first.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-1",
    "href": "ex/ex-2.html#problem-1",
    "title": "Matrix Problem Set",
    "section": "Problem 1",
    "text": "Problem 1\nGiven the following matrices:\n\\[\\mathbf{A} = \\begin{bmatrix} 1 & 3 & -2 \\\\ 4 & 0 & 5 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 2 & 1 \\\\ -1 & 3 \\\\ 0 & 4 \\end{bmatrix}, \\quad \\mathbf{C} = \\begin{bmatrix} 3 & -1 \\\\ 2 & 6 \\end{bmatrix}\\]\na) What are the dimensions of each matrix?\nb) Which of the following operations are possible? If possible, state the dimensions of the result:\n\n\\(\\mathbf{A} + \\mathbf{B}\\)\n\\(\\mathbf{A} \\times \\mathbf{B}\\)\n\\(\\mathbf{B} \\times \\mathbf{C}\\)\n\\(\\mathbf{C} \\times \\mathbf{B}\\)\n\nc) Calculate \\(\\mathbf{A} \\times \\mathbf{B}\\) (show all steps).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-2",
    "href": "ex/ex-2.html#problem-2",
    "title": "Matrix Problem Set",
    "section": "Problem 2",
    "text": "Problem 2\nGiven \\(\\mathbf{P} = \\begin{bmatrix} 2 & -1 & 4 \\\\ 3 & 0 & 1 \\end{bmatrix}\\) and \\(\\mathbf{Q} = \\begin{bmatrix} 1 & 2 \\\\ -1 & 3 \\\\ 0 & 1 \\end{bmatrix}\\)\na) Find \\(\\mathbf{P}^T\\) and \\(\\mathbf{Q}^T\\).\nb) Calculate \\(\\mathbf{P} \\times \\mathbf{Q}\\).\nc) Calculate \\((\\mathbf{P} \\times \\mathbf{Q})^T\\).\nd) Calculate \\(\\mathbf{Q}^T \\times \\mathbf{P}^T\\) and verify that \\((\\mathbf{P} \\times \\mathbf{Q})^T = \\mathbf{Q}^T \\times \\mathbf{P}^T\\).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-3",
    "href": "ex/ex-2.html#problem-3",
    "title": "Matrix Problem Set",
    "section": "Problem 3",
    "text": "Problem 3\na) Find the inverse of \\(\\mathbf{R} = \\begin{bmatrix} 3 & 1 \\\\ 2 & 1 \\end{bmatrix}\\).\nb) Verify your answer by showing that \\(\\mathbf{R} \\times \\mathbf{R}^{-1} = \\mathbf{I}\\).\nc) Explain why the matrix \\(\\mathbf{S} = \\begin{bmatrix} 2 & 4 \\\\ 1 & 2 \\end{bmatrix}\\) does not have an inverse.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-4",
    "href": "ex/ex-2.html#problem-4",
    "title": "Matrix Problem Set",
    "section": "Problem 4",
    "text": "Problem 4\na) Find \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{a}^T\\mathbf{x})\\) where \\(\\mathbf{a} = \\begin{bmatrix} 3 \\\\ -2 \\\\ 1 \\\\ 4 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix}\\).\nb) If \\(f(\\mathbf{x}) = 2x_1 - 5x_2 + 3x_3\\), write this in the form \\(\\mathbf{c}^T\\mathbf{x}\\) and find \\(\\frac{\\partial f}{\\partial \\mathbf{x}}\\).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-5",
    "href": "ex/ex-2.html#problem-5",
    "title": "Matrix Problem Set",
    "section": "Problem 5",
    "text": "Problem 5\nConsider the quadratic form \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) where \\(\\mathbf{A} = \\begin{bmatrix} 2 & 3 \\\\ 1 & 4 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\).\na) Expand \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) into scalar form.\nb) Find \\(\\mathbf{A}^T\\) and calculate \\(\\mathbf{A} + \\mathbf{A}^T\\).\nc) Use the derivative rule to find \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}^T\\mathbf{A}\\mathbf{x})\\).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-6",
    "href": "ex/ex-2.html#problem-6",
    "title": "Matrix Problem Set",
    "section": "Problem 6",
    "text": "Problem 6\nLet \\(\\mathbf{B} = \\begin{bmatrix} 4 & -1 & 2 \\\\ -1 & 3 & 0 \\\\ 2 & 0 & 5 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\).\na) Verify that \\(\\mathbf{B}\\) is symmetric.\nb) Find \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}^T\\mathbf{B}\\mathbf{x})\\) using the symmetric matrix rule.\nc) What would be the result if we used the general rule \\((\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\\) instead? Show that both methods give the same answer.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#problem-7",
    "href": "ex/ex-2.html#problem-7",
    "title": "Matrix Problem Set",
    "section": "Problem 7",
    "text": "Problem 7\nConsider the expression \\(g(\\mathbf{x}) = \\mathbf{b}^T\\mathbf{A}\\mathbf{x}\\) where: \\[\\mathbf{b} = \\begin{bmatrix} 2 \\\\ -1 \\\\ 3 \\end{bmatrix}, \\quad \\mathbf{A} = \\begin{bmatrix} 1 & 0 & 2 \\\\ 3 & -1 & 1 \\\\ 0 & 2 & 4 \\end{bmatrix}, \\quad \\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\]\na) What is the dimension of \\(g(\\mathbf{x})\\)? (Is it a scalar, vector, or matrix?)\nb) Use the rule \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{b}^T\\mathbf{A}\\mathbf{x}) = \\mathbf{A}^T\\mathbf{b}\\) to find \\(\\frac{\\partial g}{\\partial \\mathbf{x}}\\).\nc) Calculate \\(\\mathbf{A}\\mathbf{x}\\) first, then compute \\(\\mathbf{b}^T(\\mathbf{A}\\mathbf{x})\\) to expand \\(g(\\mathbf{x})\\) into scalar form.\nd) Verify your answer from part (b) by taking partial derivatives of the scalar form from part (c).",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "ex/ex-2.html#bonus-challenge",
    "href": "ex/ex-2.html#bonus-challenge",
    "title": "Matrix Problem Set",
    "section": "Bonus Challenge",
    "text": "Bonus Challenge\nHat Matrix Connection: In linear regression, we minimize the sum of squared errors: \\[SSE = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\]\nExpand this expression and identify which derivative rules from this problem set you would need to find \\(\\frac{\\partial SSE}{\\partial \\boldsymbol{\\beta}}\\). You don‚Äôt need to solve it completely, just identify the relevant derivative rules and explain how they would be applied.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Exercises",
      "Exercise 2: Matrices"
    ]
  },
  {
    "objectID": "help-project.html",
    "href": "help-project.html",
    "title": "Creating or Opening a Project",
    "section": "",
    "text": "Before starting an assignment or exercise, always create or open a project:\n\nTo create a new project:\n\nIn RStudio, go to File &gt; New Project.\nChoose whether to create a project in a new directory or within an existing directory.\nNavigate to the folder where you want your project\nClick Create Project.\n\nTo open an existing project:\n\nIn RStudio, go to File &gt; Open Project.\nBrowse to the .Rproj file of the project you want to open.\nSelect it and click Open.\n\n\nThis ensures all your files and settings are organized within the correct project environment.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Creating an RStudio Project"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Help",
    "section": "",
    "text": "Welcome to the help section! This page contains resources to help you succeed in the course, from technical setup to troubleshooting common issues. Click through the sidebar on the left."
  },
  {
    "objectID": "help.html#getting-started-with-rstudio-and-quarto",
    "href": "help.html#getting-started-with-rstudio-and-quarto",
    "title": "Help",
    "section": "Getting Started with RStudio and Quarto",
    "text": "Getting Started with RStudio and Quarto\nIf you‚Äôre new to using RStudio Pro or working with Quarto documents, check out our getting started guides.\nGetting Started Guide with RStudio Pro ‚Üí\nGetting Started Guide with Quarto ‚Üí"
  },
  {
    "objectID": "help.html#quick-links",
    "href": "help.html#quick-links",
    "title": "Help",
    "section": "Quick Links",
    "text": "Quick Links\n\nRStudio Pro Server: Access your computing environment at login.deac.wfu.edu\nCourse Schedule: Check the schedule for upcoming assignments and due dates"
  },
  {
    "objectID": "help.html#need-additional-help",
    "href": "help.html#need-additional-help",
    "title": "Help",
    "section": "Need Additional Help?",
    "text": "Need Additional Help?\nIf you can‚Äôt find what you‚Äôre looking for in our guides, don‚Äôt hesitate to reach out."
  },
  {
    "objectID": "quarto-quick-guide.html",
    "href": "quarto-quick-guide.html",
    "title": "Quarto Quick Reference Guide",
    "section": "",
    "text": "Quarto is the next-generation version of R Markdown that combines code, results, and narrative text into dynamic documents. This guide covers the essentials you‚Äôll need for STA 312.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#document-structure",
    "href": "quarto-quick-guide.html#document-structure",
    "title": "Quarto Quick Reference Guide",
    "section": "Document Structure",
    "text": "Document Structure\nEvery Quarto document starts with a YAML header (between --- lines) that contains metadata:\n---\ntitle: \"My Statistical Analysis\"\nauthor: \"Your Name\"\ndate: today\nformat: html\nexecute:\n  echo: true\n  warning: false\n---",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#basic-markdown-syntax",
    "href": "quarto-quick-guide.html#basic-markdown-syntax",
    "title": "Quarto Quick Reference Guide",
    "section": "Basic Markdown Syntax",
    "text": "Basic Markdown Syntax\n\nHeaders\n# Header 1 (largest)\n## Header 2\n### Header 3\n#### Header 4\n\n\nText Formatting\n\nBold text: **bold text** or __bold text__\nItalic text: *italic text* or _italic text_\nCode text: `code text`\nLinks: [link text](URL)\n\n\n\nLists\nUnordered lists:\n- Item 1\n- Item 2\n  - Sub-item\n  - Sub-item\nOrdered lists:\n1. First item\n2. Second item\n3. Third item",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#r-code-chunks",
    "href": "quarto-quick-guide.html#r-code-chunks",
    "title": "Quarto Quick Reference Guide",
    "section": "R Code Chunks",
    "text": "R Code Chunks\nThe power of Quarto comes from embedding R code directly in your document.\n\nBasic Code Chunk\nCode chucks start with {r}.\n```{r}\n# Your R code here\nx &lt;- c(1, 2, 3, 4, 5)\nmean(x)\n```\n\n\nCode Chunk Options\nYour code chunks can have options that are written in YAML style starting with a #| at the beginning of the line.\n```{r}\n#| label: data-setup\n#| echo: false\n#| message: false\n#| warning: false\n\n# Load libraries and data\nlibrary(tidyverse)\nlibrary(ggplot2)\n```\n\n\nCommon Chunk Options\n\n#| echo: false: Hide code, show output\n\n#| eval: false: Show code, don‚Äôt run it\n\n#| include: false: Run code, hide everything\n\n#| message: false: Hide messages\n\n#| warning: false: Hide warnings\n\n#| fig-width: 8 and #| fig-height: 6: Control plot dimensions",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#inline-r-code",
    "href": "quarto-quick-guide.html#inline-r-code",
    "title": "Quarto Quick Reference Guide",
    "section": "Inline R Code",
    "text": "Inline R Code\nYou can include R results directly in text using `r`:\nThe mean of our data is `r round(mean(x), 2)`.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#mathematical-expressions",
    "href": "quarto-quick-guide.html#mathematical-expressions",
    "title": "Quarto Quick Reference Guide",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nQuarto uses LaTeX syntax for mathematical notation:\n\nInline Math\nUse single dollar signs for inline math: $x^2 + y^2 = z^2$\n\n\nDisplay Math\nUse double dollar signs for centered display math:\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$$\n\n\nCommon Statistical Notation\n\n\n\n\n\n\n\n\nConcept\nLaTeX Code\nRendered Output\n\n\n\n\nMean\n$\\bar{x}$\n\\(\\bar{x}\\)\n\n\nStandard deviation\n$\\sigma$\n\\(\\sigma\\)\n\n\nRegression equation\n$y = \\beta_0 + \\beta_1 x + \\epsilon$\n\\(y = \\beta_0 + \\beta_1 x + \\epsilon\\)\n\n\nSums\n$\\sum_{i=1}^{n} x_i$\n\\(\\sum_{i=1}^{n} x_i\\)\n\n\nSquare root\n$\\sqrt{n}$\n\\(\\sqrt{n}\\)\n\n\nFractions\n$\\frac{a}{b}$\n\\(\\frac{a}{b}\\)\n\n\nSubscripts\n$x_i$\n\\(x_i\\)\n\n\nSuperscripts\n$x^2$\n\\(x^2\\)\n\n\nMatrices\n$\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}$\n\\(\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}\\)",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#tables",
    "href": "quarto-quick-guide.html#tables",
    "title": "Quarto Quick Reference Guide",
    "section": "Tables",
    "text": "Tables\n\nSimple Tables\n| Variable | Mean | SD   |\n|----------|------|------|\n| Height   | 68.2 | 3.1  |\n| Weight   | 155  | 22.5 |\n\n\nTables from R Code\n```{r}\n#| label: summary-table\n#| tbl-cap: \"Summary Statistics\"\n\nlibrary(knitr)\nsummary_stats &lt;- data.frame(\n  Variable = c(\"Height\", \"Weight\"),\n  Mean = c(68.2, 155.0),\n  SD = c(3.1, 22.5)\n)\nkable(summary_stats)\n```",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#figures",
    "href": "quarto-quick-guide.html#figures",
    "title": "Quarto Quick Reference Guide",
    "section": "Figures",
    "text": "Figures\n\nPlots with Captions\n```{r}\n#| label: fig-scatter\n#| fig-cap: \"Relationship between height and weight\"\n#| fig-width: 6\n#| fig-height: 4\n\nggplot(data, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Height (inches)\", y = \"Weight (lbs)\")\n```",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#cross-references",
    "href": "quarto-quick-guide.html#cross-references",
    "title": "Quarto Quick Reference Guide",
    "section": "Cross-References",
    "text": "Cross-References\nYou can reference figures, tables, and equations:\n\nReference a figure: @fig-scatter\n\nReference a table: @tbl-summary\n\nReference an equation: @eq-regression\n\nFor equations with labels:\n$$y = \\beta_0 + \\beta_1 x + \\epsilon$$ {#eq-regression}",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#callout-blocks",
    "href": "quarto-quick-guide.html#callout-blocks",
    "title": "Quarto Quick Reference Guide",
    "section": "Callout Blocks",
    "text": "Callout Blocks\nQuarto provides special callout blocks for important information:\n::: {.callout-note}\nThis is a note callout.\n:::\n\n::: {.callout-warning}\nThis is a warning callout.\n:::\n\n::: {.callout-important}\nThis is an important callout.\n:::",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#rendering-your-document",
    "href": "quarto-quick-guide.html#rendering-your-document",
    "title": "Quarto Quick Reference Guide",
    "section": "Rendering Your Document",
    "text": "Rendering Your Document\nTo render your Quarto document:\n\nIn RStudio: Click the ‚ÄúRender‚Äù button\n\nCommand line: Run quarto render filename.qmd\n\nPreview: Use quarto preview filename.qmd for live preview",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "quarto-quick-guide.html#tips-for-statistical-writing",
    "href": "quarto-quick-guide.html#tips-for-statistical-writing",
    "title": "Quarto Quick Reference Guide",
    "section": "Tips for Statistical Writing",
    "text": "Tips for Statistical Writing\n\nAlways explain your code: Use comments (#) and narrative text\nRound numbers appropriately: Use round() function for inline code\nLabel your chunks: Makes debugging easier\nInclude figure captions: Helps with interpretation",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Computing",
      "Quarto Quick Guide"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "\n Schedule",
    "section": "",
    "text": "Note: The timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\nweek\n\n\ndate\n\n\ntopic\n\n\nprepare\n\n\nslides\n\n\nexercises\n\n\n\n\n\n1\n\n\n27 August\n\n\nWelcome to Linear Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR and Reproducible Workflows\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n29 August\n\n\nMatrix Refresher\n\n\n\n\n\n\n\n\n\n\n\n\n2\n\n\n3 September\n\n\nMatrix Workshop\n\n\n\n\n\n\n\n\n\n\n\n\n2\n\n\n5 September\n\n\nLinear Regression Fundamentals\n\n\nFaraway Sections 1.3 - 1.4\n\n\n\n\n\n\n\n\n\n\n3\n\n\n10 September\n\n\nLinear Regression Fundamentals (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n3\n\n\n12 September\n\n\nMultiple Linear Regression\n\n\nFaraway Sections 2.1-2.6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeriving the Hat Matrix\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\n17 September\n\n\nNo Class\n\n\n\n\n\n\n\n\n\n\n\n\n4\n\n\n19 September\n\n\nProperties of Random Vectors\n\n\nFaraway Section 2.8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGauss Markov Theorem\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\n24 September\n\n\nGauss Markov Theorem (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n5\n\n\n26 September\n\n\nResidual Sum of Squares\n\n\nFaraway Sections 2.9, 3.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoodness of Fit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis Testing\n\n\n\n\n\n\n\n\n\n\n\n\n6\n\n\n1 October\n\n\nPractical Workshop\n\n\n\n\n\n\n\n\n\n\n\n\n6\n\n\n3 October\n\n\nMidterm review\n\n\n\n\n\n\n\n\n\n\n\n\n7\n\n\n8 October\n\n\nMidterm (In Class)\n\n\n\n\n\n\n\n\n\n\n\n\n7\n\n\n10 October\n\n\nMidterm (Out of Class)\n\n\n\n\n\n\n\n\n\n\n\n\n8\n\n\n15 October\n\n\nMidterm Recap\n\n\n\n\n\n\n\n\n\n\n\n\n8\n\n\n17 October\n\n\nConfidence Intervals\n\n\nFaraway Sections 3.4-3.6\n\n\n\n\n\n\n\n\n\n\n9\n\n\n22 October\n\n\nConfidence Intervals (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n9\n\n\n24 October\n\n\nDiagnostics\n\n\nFaraway Chapter 6\n\n\n\n\n\n\n\n\n\n\n10\n\n\n29 October\n\n\nDiagnostics (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n10\n\n\n31 October\n\n\nTransformations\n\n\nFaraway Chapter 9\n\n\n\n\n\n\n\n\n\n\n11\n\n\n5 November\n\n\nTransformations (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n11\n\n\n7 November\n\n\nPrediction & Prediction Intervals\n\n\nFaraway Chapter 4\n\n\n\n\n\n\n\n\n\n\n12\n\n\n12 November\n\n\nPrediction (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n12\n\n\n14 November\n\n\nExplanation\n\n\nFaraway Chapter 5\n\n\n\n\n\n\n\n\n\n\n13\n\n\n19 November\n\n\nCausal Inference (Workshop)\n\n\n\n\n\n\n\n\n\n\n\n\n13\n\n\n21 November\n\n\nFinal Project\n\n\n\n\n\n\n\n\n\n\n\n\n14\n\n\n26 November\n\n\nThanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n14\n\n\n28 November\n\n\nThanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n15\n\n\n3 December\n\n\nFinal Presentation (Out of Class)\n\n\n\n\n\n\n\n\n\n\n\n\n15\n\n\n5 December\n\n\nFinal Presentation (Out of Class)",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/02-slides.html#what-is-a-matrix",
    "href": "slides/02-slides.html#what-is-a-matrix",
    "title": "Matrix Algebra Fundamentals",
    "section": "What is a Matrix?",
    "text": "What is a Matrix?\n\nA matrix is a rectangular array of numbers arranged in rows and columns\nWritten using square brackets or parentheses\nEach number in the matrix is called an element or entry"
  },
  {
    "objectID": "slides/02-slides.html#what-is-a-matrix-1",
    "href": "slides/02-slides.html#what-is-a-matrix-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "What is a Matrix?",
    "text": "What is a Matrix?\n\\[\\mathbf{A} = \\begin{bmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-dimensions",
    "href": "slides/02-slides.html#matrix-dimensions",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Dimensions",
    "text": "Matrix Dimensions\n\nRows are horizontal ‚ÜîÔ∏é\n\n\nColumns are vertical ‚Üï\n\n\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\require{color}\\colorbox{#eec8e1}{$a_{11}$} & \\colorbox{#eec8e1}{$a_{12}$} & \\colorbox{#eec8e1}{$a_{13}$} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix} \\leftarrow \\text{Row 1}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-dimensions-1",
    "href": "slides/02-slides.html#matrix-dimensions-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Dimensions",
    "text": "Matrix Dimensions\nRows are horizontal ‚ÜîÔ∏é\nColumns are vertical ‚Üï\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\require{color}a_{11} & a_{12} & a_{13} \\\\\n\\colorbox{#eec8e1}{$a_{21}$} & \\colorbox{#eec8e1}{$a_{22}$} & \\colorbox{#eec8e1}{$a_{23}$} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix} \\leftarrow \\text{Row 2}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-dimensions-2",
    "href": "slides/02-slides.html#matrix-dimensions-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Dimensions",
    "text": "Matrix Dimensions\nRows are horizontal ‚ÜîÔ∏é\nColumns are vertical ‚Üï\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\require{color}a_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\n\\colorbox{#eec8e1}{$a_{31}$} & \\colorbox{#eec8e1}{$a_{32}$} & \\colorbox{#eec8e1}{$a_{33}$}\n\\end{bmatrix} \\leftarrow \\text{Row 3}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-dimensions-3",
    "href": "slides/02-slides.html#matrix-dimensions-3",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Dimensions",
    "text": "Matrix Dimensions\nRows are horizontal ‚ÜîÔ∏é\nColumns are vertical ‚Üï\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\colorbox{#eec8e1}{$a_{11}$} & a_{12} & a_{13} \\\\\n\\colorbox{#eec8e1}{$a_{21}$} & a_{22} & a_{23} \\\\\n\\colorbox{#eec8e1}{$a_{31}$} & a_{32} & a_{33}\n\\end{bmatrix} \\leftarrow \\text{Column 1}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-size-n-p",
    "href": "slides/02-slides.html#matrix-size-n-p",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Size: n √ó p",
    "text": "Matrix Size: n √ó p\n\nA matrix with n rows and p columns is called an n √ó p matrix\n\n\n\\[\\mathbf{A}_{3 \\times 3} = \\begin{bmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\\]\nThis is a 3 √ó 3 matrix (3 rows, 3 columns)"
  },
  {
    "objectID": "slides/02-slides.html#matrix-size-n-p-1",
    "href": "slides/02-slides.html#matrix-size-n-p-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Size: n √ó p",
    "text": "Matrix Size: n √ó p\nA matrix with n rows and p columns is called an n √ó p matrix\n\\[\\mathbf{B}_{2 \\times 4} = \\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & b_{14} \\\\\nb_{21} & b_{22} & b_{23} & b_{24}\n\\end{bmatrix}\\]\nThis is a 2 √ó 4 matrix (2 rows, 4 columns)"
  },
  {
    "objectID": "slides/02-slides.html#examples-of-different-matrix-sizes",
    "href": "slides/02-slides.html#examples-of-different-matrix-sizes",
    "title": "Matrix Algebra Fundamentals",
    "section": "Examples of Different Matrix Sizes",
    "text": "Examples of Different Matrix Sizes\n\n\nRow vector (1 √ó p): \\[\\mathbf{r} = \\begin{bmatrix} 1 & 3 & 5 & 7 \\end{bmatrix}\\]\n\n\n\nColumn vector (n √ó 1): \\[\\mathbf{c} = \\begin{bmatrix} 2 \\\\ 4 \\\\ 6 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#examples-of-different-matrix-sizes-1",
    "href": "slides/02-slides.html#examples-of-different-matrix-sizes-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Examples of Different Matrix Sizes",
    "text": "Examples of Different Matrix Sizes\nSquare matrix (n √ó n): \\[\\mathbf{S} = \\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-addition",
    "href": "slides/02-slides.html#matrix-addition",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Addition",
    "text": "Matrix Addition\n\nMatrices can be added only if they have the same dimensions\n\n\nAdd corresponding elements: \\[\\mathbf{A} + \\mathbf{B} = \\begin{bmatrix} a_{11} + b_{11} & a_{12} + b_{12} \\\\ a_{21} + b_{21} & a_{22} + b_{22} \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-addition-1",
    "href": "slides/02-slides.html#matrix-addition-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Addition",
    "text": "Matrix Addition\n\nExample: \\[\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} + \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}\\]\n\n\n\\[= \\begin{bmatrix} \\color{red}{1+5} & \\color{blue}{2+6} \\\\ \\color{green}{3+7} & \\color{purple}{4+8} \\end{bmatrix} = \\begin{bmatrix} \\color{red}{6} & \\color{blue}{8} \\\\ \\color{green}{10} & \\color{purple}{12} \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-addition",
    "href": "slides/02-slides.html#you-try-matrix-addition",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Addition",
    "text": "You Try: Matrix Addition\n\nProblem: Add these matrices \\(\\mathbf{A} = \\begin{bmatrix} 3 & -1 & 2 \\\\ 0 & 4 & -3 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 1 & 2 & -1 \\\\ 5 & -2 & 1 \\end{bmatrix}\\)\n\n\nYou Try: \\(\\mathbf{A} + \\mathbf{B} = ?\\)\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/02-slides.html#lets-verify-in-r",
    "href": "slides/02-slides.html#lets-verify-in-r",
    "title": "Matrix Algebra Fundamentals",
    "section": " Let‚Äôs verify in R",
    "text": "Let‚Äôs verify in R\n\n\nA &lt;- matrix(c(3, -1, 2,\n              0, 4, -3), \n            nrow = 2, byrow = TRUE)\nB &lt;- matrix(c(1, 2, -1,\n              5, -2, 1),\n            nrow = 2, byrow = TRUE)\nA + B\n\n     [,1] [,2] [,3]\n[1,]    4    1    1\n[2,]    5    2   -2"
  },
  {
    "objectID": "slides/02-slides.html#matrix-addition-dimension-requirements",
    "href": "slides/02-slides.html#matrix-addition-dimension-requirements",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Addition: Dimension Requirements",
    "text": "Matrix Addition: Dimension Requirements\n\n\nThis works ‚úì\n\n\\[\\colorbox{#eec8e1}{$\\mathbf{A}_{2 \\times 3} + \\mathbf{B}_{2 \\times 3} = \\mathbf{C}_{2 \\times 3}$}\\]\n\n\n\n\nThis doesn‚Äôt work ‚úó\n\n\\[\\colorbox{#eec8e1}{$\\mathbf{A}_{2 \\times 3} + \\mathbf{B}_{3 \\times 2} = \\text{?}$}\\]\n\n\n\nThe matrices must have exactly the same dimensions to be added!"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-the-basics",
    "href": "slides/02-slides.html#matrix-multiplication-the-basics",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: The Basics",
    "text": "Matrix Multiplication: The Basics\n\nMatrix multiplication is NOT element-wise multiplication\nFor \\(\\mathbf{A} \\times \\mathbf{B}\\) to be defined the number of columns in A must equal number of rows in B (inner dimensions must match!)\nIf \\(\\mathbf{A}\\) is \\(m \\times n\\) and \\(\\mathbf{B}\\) is \\(n \\times p\\), then: \\[\\mathbf{A}_{m \\times n} \\times \\mathbf{B}_{n \\times p} = \\mathbf{C}_{m \\times p}\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-dimensions",
    "href": "slides/02-slides.html#you-try-matrix-dimensions",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Dimensions",
    "text": "You Try: Matrix Dimensions\n\nProblem: Can these matrices be multiplied? If yes, what‚Äôs the resulting dimension?\n\\(\\mathbf{A}_{3 \\times 2} \\times \\mathbf{B}_{2 \\times 4} = ?\\)\n\\(\\mathbf{C}_{2 \\times 5} \\times \\mathbf{D}_{3 \\times 2} = ?\\)\n\n\nSolutions:\n\n\\(\\mathbf{A}_{3 \\times 2} \\times \\mathbf{B}_{2 \\times 4} = \\mathbf{Result}_{3 \\times 4}\\) ‚úì (inner dimensions match: 2 = 2)\n\\(\\mathbf{C}_{2 \\times 5} \\times \\mathbf{D}_{3 \\times 2}\\) = undefined ‚úó (inner dimensions don‚Äôt match: 5 ‚â† 3)\n\n\n\n\n\n‚àí+\n02:00"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}&\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-1",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}\\colorbox{#eec8e1}{}&\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-2",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\\begin{bmatrix} \\colorbox{#eec8e1}{1} & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}{5} & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}\\colorbox{#eec8e1}{(1)(5)}&\\\\&\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-3",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-3",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\\begin{bmatrix} \\colorbox{#eec8e1}{1} & \\colorbox{#eec8e1}2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}{5} & 6 \\\\ \\colorbox{#eec8e1}7 & 8 \\end{bmatrix}=\\begin{bmatrix}\\colorbox{#eec8e1}{(1)(5) + (2)(7)}&\\\\&\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-4",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-4",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\\begin{bmatrix} \\colorbox{#eec8e1}{1} & \\colorbox{#eec8e1}2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}{5} & 6 \\\\ \\colorbox{#eec8e1}7 & 8 \\end{bmatrix}=\\begin{bmatrix}\\colorbox{#eec8e1}{19}&\\\\&\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-5",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-5",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&\\colorbox{#eec8e1}{ }\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-6",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-6",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} \\colorbox{#eec8e1}1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&\\colorbox{#eec8e1}{(1)(6)}\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-7",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-7",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} \\colorbox{#eec8e1}1 & \\colorbox{#eec8e1}2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & \\colorbox{#eec8e1}8 \\end{bmatrix}=\\begin{bmatrix}19&\\colorbox{#eec8e1}{(1)(6)+(2)(8)}\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-8",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-8",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} \\colorbox{#eec8e1}1 & \\colorbox{#eec8e1}2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & \\colorbox{#eec8e1}8 \\end{bmatrix}=\\begin{bmatrix}19&\\colorbox{#eec8e1}{22}\\\\&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-9",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-9",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\\\colorbox{#eec8e1}{ }&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-10",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-10",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\\\colorbox{#eec8e1}{(3)(5) }&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-11",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-11",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & \\colorbox{#eec8e1}4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}5 & 6 \\\\ \\colorbox{#eec8e1}7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\\\colorbox{#eec8e1}{(3)(5) +(4)(7)}&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-12",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-12",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & \\colorbox{#eec8e1}4 \\end{bmatrix} \\times \\begin{bmatrix} \\colorbox{#eec8e1}5 & 6 \\\\ \\colorbox{#eec8e1}7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\\\colorbox{#eec8e1}{43}&\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-13",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-13",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\43&\\colorbox{#eec8e1}{ }\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-14",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-14",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & 4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & 8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\43&\\colorbox{#eec8e1}{(3)(6) }\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-15",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-15",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & \\colorbox{#eec8e1}4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & \\colorbox{#eec8e1}8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\43&\\colorbox{#eec8e1}{(3)(6)+(4)(8) }\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-step-by-step-16",
    "href": "slides/02-slides.html#matrix-multiplication-step-by-step-16",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Step by Step",
    "text": "Matrix Multiplication: Step by Step\n\\[\n\\begin{bmatrix} 1 & 2 \\\\ \\colorbox{#eec8e1}3 & \\colorbox{#eec8e1}4 \\end{bmatrix} \\times \\begin{bmatrix} 5 & \\colorbox{#eec8e1}6 \\\\ 7 & \\colorbox{#eec8e1}8 \\end{bmatrix}=\\begin{bmatrix}19&22{}\\\\43&\\colorbox{#eec8e1}{52}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-multiplication",
    "href": "slides/02-slides.html#you-try-matrix-multiplication",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Multiplication",
    "text": "You Try: Matrix Multiplication\n\nProblem: Multiply these matrices \\(\\mathbf{A} = \\begin{bmatrix} 2 & 3 \\\\ 1 & 4 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 1 & 0 \\\\ 2 & 1 \\end{bmatrix}\\)\n\n\nYou Try: \\(\\mathbf{A} \\times \\mathbf{B} = ?\\)\n\n\nSolution:\n\\(\\mathbf{A} \\times \\mathbf{B} = \\begin{bmatrix} 8 & 3 \\\\ 9 & 4 \\end{bmatrix}\\)\n\n\n\n\n‚àí+\n05:00"
  },
  {
    "objectID": "slides/02-slides.html#lets-verify-in-r-1",
    "href": "slides/02-slides.html#lets-verify-in-r-1",
    "title": "Matrix Algebra Fundamentals",
    "section": " Let‚Äôs verify in R",
    "text": "Let‚Äôs verify in R\n\n\nA &lt;- matrix(c(2, 3,\n              1, 4), \n            nrow = 2, byrow = TRUE)\nB &lt;- matrix(c(1, 0,\n              2, 1),\n            nrow = 2, byrow = TRUE)\nA %*% B\n\n     [,1] [,2]\n[1,]    8    3\n[2,]    9    4"
  },
  {
    "objectID": "slides/02-slides.html#matrix-multiplication-dimension-examples",
    "href": "slides/02-slides.html#matrix-multiplication-dimension-examples",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Multiplication: Dimension Examples",
    "text": "Matrix Multiplication: Dimension Examples\n\n\nValid multiplications:\n\n\\(\\mathbf{A}_{2 \\times 3} \\times \\mathbf{B}_{3 \\times 4} = \\mathbf{C}_{2 \\times 4}\\) ‚úì\n\\(\\mathbf{A}_{5 \\times 2} \\times \\mathbf{B}_{2 \\times 1} = \\mathbf{C}_{5 \\times 1}\\) ‚úì\n\n\n\n\nInvalid multiplications:\n\n\\(\\mathbf{A}_{2 \\times 3} \\times \\mathbf{B}_{4 \\times 2}\\) ‚úó (3 ‚â† 4)\n\\(\\mathbf{A}_{3 \\times 5} \\times \\mathbf{B}_{2 \\times 3}\\) ‚úó (5 ‚â† 2)\n\n\n\nRemember: Inner dimensions must match!"
  },
  {
    "objectID": "slides/02-slides.html#matrix-transpose",
    "href": "slides/02-slides.html#matrix-transpose",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Transpose",
    "text": "Matrix Transpose\n\nThe transpose of matrix \\(\\mathbf{A}\\) is denoted \\(\\mathbf{A}^T\\) or \\(\\mathbf{A}'\\)\n\n\nFlip rows and columns\n\nRow 1 becomes Column 1\nRow 2 becomes Column 2, etc."
  },
  {
    "objectID": "slides/02-slides.html#matrix-transpose-1",
    "href": "slides/02-slides.html#matrix-transpose-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Transpose",
    "text": "Matrix Transpose\n\n\n\n\\[\\mathbf{A} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}_{2 \\times 3}\\]\n\n\n\n\\[\\mathbf{A}^T = \\begin{bmatrix} 1 & 4 \\\\ 2 & 5 \\\\ 3 & 6 \\end{bmatrix}_{3 \\times 2}\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-transpose",
    "href": "slides/02-slides.html#you-try-matrix-transpose",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Transpose",
    "text": "You Try: Matrix Transpose\n\nFind the transpose of this matrix \\(\\mathbf{A} = \\begin{bmatrix} 1 & 4 & 7 \\\\ 2 & 5 & 8 \\end{bmatrix}\\) \\(A^T= ?\\)\n\n\nSolution: \\(\\mathbf{A}^T = \\begin{bmatrix} 1 & 2 \\\\ 4 & 5 \\\\ 7 & 8 \\end{bmatrix}\\)\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/02-slides.html#lets-verify-in-r-2",
    "href": "slides/02-slides.html#lets-verify-in-r-2",
    "title": "Matrix Algebra Fundamentals",
    "section": " Let‚Äôs verify in R",
    "text": "Let‚Äôs verify in R\n\n\nA &lt;- matrix(c(1, 4, 7,\n              2, 5, 8), \n            nrow = 2, byrow = TRUE)\n\nt(A)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    4    5\n[3,]    7    8"
  },
  {
    "objectID": "slides/02-slides.html#transpose-properties",
    "href": "slides/02-slides.html#transpose-properties",
    "title": "Matrix Algebra Fundamentals",
    "section": "Transpose Properties",
    "text": "Transpose Properties\nIf \\(\\mathbf{A}\\) is \\(m \\times n\\), then \\(\\mathbf{A}^T\\) is \\(n \\times m\\)"
  },
  {
    "objectID": "slides/02-slides.html#transpose-properties-1",
    "href": "slides/02-slides.html#transpose-properties-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Transpose Properties",
    "text": "Transpose Properties\n\n\\((\\mathbf{A}^T)^T = \\mathbf{A}\\)\n\\((\\mathbf{A} + \\mathbf{B})^T = \\mathbf{A}^T + \\mathbf{B}^T\\)\n\\((\\mathbf{AB})^T = \\mathbf{B}^T\\mathbf{A}^T\\) (order reverses!)\nSymmetric Matrix: \\(\\mathbf{A} = \\mathbf{A}^T\\)"
  },
  {
    "objectID": "slides/02-slides.html#symmetric-matrix",
    "href": "slides/02-slides.html#symmetric-matrix",
    "title": "Matrix Algebra Fundamentals",
    "section": "Symmetric Matrix",
    "text": "Symmetric Matrix\n\\(\\mathbf{A} = \\mathbf{A}^T\\)\n\\[\\mathbf{S} = \\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & 4 & 5 \\\\ 3 & 5 & 6 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#the-identity-matrix",
    "href": "slides/02-slides.html#the-identity-matrix",
    "title": "Matrix Algebra Fundamentals",
    "section": "The Identity Matrix",
    "text": "The Identity Matrix\n\nThe identity matrix \\(\\mathbf{I}\\) is the matrix equivalent of the number 1\n\n\n\nSquare matrix with 1‚Äôs on the diagonal and 0‚Äôs elsewhere\nActs as the multiplicative identity: \\(\\mathbf{AI} = \\mathbf{IA} = \\mathbf{A}\\)"
  },
  {
    "objectID": "slides/02-slides.html#the-identity-matrix-1",
    "href": "slides/02-slides.html#the-identity-matrix-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "The Identity Matrix",
    "text": "The Identity Matrix\n\\[\\mathbf{I}_2 = \\begin{bmatrix} \\color{red}{1} & 0 \\\\ 0 & \\color{red}{1} \\end{bmatrix}, \\quad \\mathbf{I}_3 = \\begin{bmatrix} \\color{red}{1} & 0 & 0 \\\\ 0 & \\color{red}{1} & 0 \\\\ 0 & 0 & \\color{red}{1} \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#the-identity-matrix-2",
    "href": "slides/02-slides.html#the-identity-matrix-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "The Identity Matrix",
    "text": "The Identity Matrix\nExample: \\[\\begin{bmatrix} 2 & 3 \\\\ 4 & 5 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 2 & 3 \\\\ 4 & 5 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-identity-matrix",
    "href": "slides/02-slides.html#you-try-identity-matrix",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Identity Matrix",
    "text": "You Try: Identity Matrix\n\nProblem: Verify that this multiplication gives the identity property \\(\\begin{bmatrix} 3 & -1 \\\\ 2 & 4 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = ?\\)\n\n\nSolution: \\(= \\begin{bmatrix} 3 & -1 \\\\ 2 & 4 \\end{bmatrix}\\) ‚úì (Original matrix unchanged!)\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/02-slides.html#lets-verify-in-r-3",
    "href": "slides/02-slides.html#lets-verify-in-r-3",
    "title": "Matrix Algebra Fundamentals",
    "section": " Let‚Äôs verify in R",
    "text": "Let‚Äôs verify in R\n\n\nA &lt;- matrix(c(3, -1,\n              2, 4), \n            nrow = 2, byrow = TRUE)\nI &lt;- diag(2)\nA %*% I\n\n     [,1] [,2]\n[1,]    3   -1\n[2,]    2    4"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse",
    "href": "slides/02-slides.html#matrix-inverse",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nThe inverse of matrix \\(\\mathbf{A}\\) is denoted \\(\\mathbf{A}^{-1}\\)\n\n\nDefinition: \\(\\mathbf{AA}^{-1} = \\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}\\)"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse-1",
    "href": "slides/02-slides.html#matrix-inverse-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nRequirements for inverse to exist:\n- Matrix must be square (n √ó n)\n- Matrix must be non-singular (determinant ‚â† 0)"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse-2",
    "href": "slides/02-slides.html#matrix-inverse-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\n2 √ó 2 Formula: For \\(\\mathbf{A} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\)\n\\[\\mathbf{A}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse-example",
    "href": "slides/02-slides.html#matrix-inverse-example",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse: Example",
    "text": "Matrix Inverse: Example\n\n\\[\\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 6 & 2 \\end{bmatrix}\\]\n\n\nStep 1: Calculate determinant \\[\\text{det}(\\mathbf{A}) = (2)(2) - (1)(6) = 4 - 6 = -2\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse-example-1",
    "href": "slides/02-slides.html#matrix-inverse-example-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse: Example",
    "text": "Matrix Inverse: Example\n\\[\\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 6 & 2 \\end{bmatrix}\\]\n\nStep 2: Apply formula \\[\\mathbf{A}^{-1} = \\frac{1}{-2} \\begin{bmatrix} 2 & -1 \\\\ -6 & 2 \\end{bmatrix} = \\begin{bmatrix} -1 & 0.5 \\\\ 3 & -1 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#matrix-inverse-example-2",
    "href": "slides/02-slides.html#matrix-inverse-example-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Inverse: Example",
    "text": "Matrix Inverse: Example\n\\[\\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 6 & 2 \\end{bmatrix}\\]\n\nVerify: \\[\\mathbf{AA}^{-1} = \\begin{bmatrix} 2 & 1 \\\\ 6 & 2 \\end{bmatrix} \\begin{bmatrix} -1 & 0.5 \\\\ 3 & -1 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\mathbf{I}\\]"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-inverse",
    "href": "slides/02-slides.html#you-try-matrix-inverse",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Inverse",
    "text": "You Try: Matrix Inverse\n\nProblem: Find the inverse of this matrix \\(\\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 4 & 3 \\end{bmatrix}\\)\n\n\nSolution: 1. \\(\\text{det}(\\mathbf{A}) = (1)(3) - (2)(4) = 3 - 8 = -5\\)\n2. \\(\\mathbf{A}^{-1} = \\frac{1}{-5} \\begin{bmatrix} 3 & -2 \\\\ -4 & 1 \\end{bmatrix} = \\begin{bmatrix} -0.6 & 0.4 \\\\ 0.8 & -0.2 \\end{bmatrix}\\)\nCheck: \\(\\mathbf{AA}^{-1} = \\begin{bmatrix} 1 & 2 \\\\ 4 & 3 \\end{bmatrix} \\begin{bmatrix} -0.6 & 0.4 \\\\ 0.8 & -0.2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\) ‚úì\n\n\n\n\n‚àí+\n06:00"
  },
  {
    "objectID": "slides/02-slides.html#lets-verify-in-r-4",
    "href": "slides/02-slides.html#lets-verify-in-r-4",
    "title": "Matrix Algebra Fundamentals",
    "section": " Let‚Äôs verify in R",
    "text": "Let‚Äôs verify in R\n\n\nA &lt;- matrix(c(1, 2, \n              4, 3), \n            nrow = 2, byrow = TRUE)\nsolve(A)\n\n     [,1] [,2]\n[1,] -0.6  0.4\n[2,]  0.8 -0.2\n\nround(A %*% solve(A), 10)\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1"
  },
  {
    "objectID": "slides/02-slides.html#what-about-matrices-of-higher-dimension",
    "href": "slides/02-slides.html#what-about-matrices-of-higher-dimension",
    "title": "Matrix Algebra Fundamentals",
    "section": "What about matrices of higher dimension?",
    "text": "What about matrices of higher dimension?\n\nLife is short! Let‚Äôs just use R.\nBe sure to check the determinant! (it cannot be 0)\n\n\nA &lt;- matrix(c(1, 2,\n              2, 4),\n            nrow = 2, byrow = TRUE)\ndet(A)\n\n[1] 0"
  },
  {
    "objectID": "slides/02-slides.html#special-matrix-types",
    "href": "slides/02-slides.html#special-matrix-types",
    "title": "Matrix Algebra Fundamentals",
    "section": "Special Matrix Types",
    "text": "Special Matrix Types\n\nDiagonal Matrix: Non-zero elements only on the main diagonal\n\\[\\mathbf{D} = \\begin{bmatrix} d_1 & 0 & 0 \\\\ 0 & d_2 & 0 \\\\ 0 & 0 & d_3 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#special-matrix-types-1",
    "href": "slides/02-slides.html#special-matrix-types-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Special Matrix Types",
    "text": "Special Matrix Types\n\nOrthogonal Matrix: \\(\\mathbf{Q}^T\\mathbf{Q} = \\mathbf{I}\\) (columns are orthonormal)"
  },
  {
    "objectID": "slides/02-slides.html#special-matrix-types-2",
    "href": "slides/02-slides.html#special-matrix-types-2",
    "title": "Matrix Algebra Fundamentals",
    "section": "Special Matrix Types",
    "text": "Special Matrix Types\n\nPositive Definite: \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x} &gt; 0\\) for all \\(\\mathbf{x} \\neq \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/02-slides.html#special-matrix-types-3",
    "href": "slides/02-slides.html#special-matrix-types-3",
    "title": "Matrix Algebra Fundamentals",
    "section": "Special Matrix Types",
    "text": "Special Matrix Types\n\nSymmetric Matrix: \\(\\mathbf{A} = \\mathbf{A}^T\\)"
  },
  {
    "objectID": "slides/02-slides.html#you-try-special-matrices",
    "href": "slides/02-slides.html#you-try-special-matrices",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Special Matrices",
    "text": "You Try: Special Matrices\n\nProblem: Identify the type of each matrix \\(\\mathbf{A} = \\begin{bmatrix} 2 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 1 & 4 \\\\ 4 & 2 \\end{bmatrix}, \\quad \\mathbf{C} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\)\n\n\nSolutions: - Matrix A: Diagonal matrix (non-zero elements only on main diagonal) - Matrix B: Symmetric matrix (\\(\\mathbf{B} = \\mathbf{B}^T\\) since \\(b_{12} = b_{21} = 4\\)) - Matrix C: General matrix (no special properties)\n\n\n\n\n‚àí+\n02:00"
  },
  {
    "objectID": "slides/02-slides.html#vector-derivatives-introduction",
    "href": "slides/02-slides.html#vector-derivatives-introduction",
    "title": "Matrix Algebra Fundamentals",
    "section": "Vector Derivatives: Introduction",
    "text": "Vector Derivatives: Introduction\n\nWhy do we need derivatives of vectors?\n\nEssential for optimization in statistics and machine learning\nKey to deriving least squares solutions\nFoundation for understanding the hat matrix"
  },
  {
    "objectID": "slides/02-slides.html#vector-derivatives-notation",
    "href": "slides/02-slides.html#vector-derivatives-notation",
    "title": "Matrix Algebra Fundamentals",
    "section": "Vector Derivatives: Notation",
    "text": "Vector Derivatives: Notation\n\nLet \\(\\mathbf{a} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_n \\end{bmatrix}\\) and \\(\\mathbf{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{bmatrix}\\) be column vectors"
  },
  {
    "objectID": "slides/02-slides.html#derivative-rule-linear-form",
    "href": "slides/02-slides.html#derivative-rule-linear-form",
    "title": "Matrix Algebra Fundamentals",
    "section": "Derivative Rule: Linear Form",
    "text": "Derivative Rule: Linear Form\n\nRule: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{a}'\\mathbf{x}) = \\mathbf{a}\\)\n\n\nIn words: The derivative of a linear form \\(\\mathbf{a}'\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is simply \\(\\mathbf{a}\\)"
  },
  {
    "objectID": "slides/02-slides.html#derivative-rule-example",
    "href": "slides/02-slides.html#derivative-rule-example",
    "title": "Matrix Algebra Fundamentals",
    "section": "Derivative Rule: Example",
    "text": "Derivative Rule: Example\n\nLet \\(\\mathbf{a} = \\begin{bmatrix} 2 \\\\ 3 \\\\ 1 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\\)\n\n\nThen \\(\\mathbf{a}'\\mathbf{x} = 2x_1 + 3x_2 + x_3\\)\n\n\nDerivative: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(2x_1 + 3x_2 + x_3) = \\begin{bmatrix} 2 \\\\ 3 \\\\ 1 \\end{bmatrix} = \\mathbf{a}\\)"
  },
  {
    "objectID": "slides/02-slides.html#you-try-vector-derivatives",
    "href": "slides/02-slides.html#you-try-vector-derivatives",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Vector Derivatives",
    "text": "You Try: Vector Derivatives\n\nProblem: Find \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{c}'\\mathbf{x})\\) where \\(\\mathbf{c} = \\begin{bmatrix} 5 \\\\ -2 \\\\ 4 \\end{bmatrix}\\)\n\n\nSolution: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{c}'\\mathbf{x}) = \\mathbf{c} = \\begin{bmatrix} 5 \\\\ -2 \\\\ 4 \\end{bmatrix}\\)\n\n\n\n\n‚àí+\n03:00"
  },
  {
    "objectID": "slides/02-slides.html#matrix-derivatives-quadratic-forms",
    "href": "slides/02-slides.html#matrix-derivatives-quadratic-forms",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Derivatives: Quadratic Forms",
    "text": "Matrix Derivatives: Quadratic Forms\n\nQuadratic form: \\(\\mathbf{x}'\\mathbf{A}\\mathbf{x}\\) where \\(\\mathbf{A}\\) is an \\(n \\times n\\) matrix\n\n\nExample: \\(\\mathbf{x}'\\mathbf{A}\\mathbf{x} = \\begin{bmatrix} x_1 & x_2 \\end{bmatrix} \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/02-slides.html#matrix-derivatives-quadratic-forms-1",
    "href": "slides/02-slides.html#matrix-derivatives-quadratic-forms-1",
    "title": "Matrix Algebra Fundamentals",
    "section": "Matrix Derivatives: Quadratic Forms",
    "text": "Matrix Derivatives: Quadratic Forms\n\nExpanding the 2√ó2 case: \\[\\mathbf{x}'\\mathbf{A}\\mathbf{x} = a_{11}x_1^2 + (a_{12} + a_{21})x_1x_2 + a_{22}x_2^2\\]"
  },
  {
    "objectID": "slides/02-slides.html#derivative-rule-3-quadratic-forms",
    "href": "slides/02-slides.html#derivative-rule-3-quadratic-forms",
    "title": "Matrix Algebra Fundamentals",
    "section": "Derivative Rule 3: Quadratic Forms",
    "text": "Derivative Rule 3: Quadratic Forms\n\nRule: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{A}\\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}')\\mathbf{x}\\)\n\n\nSpecial case: If \\(\\mathbf{A}\\) is symmetric (\\(\\mathbf{A} = \\mathbf{A}'\\)), then: \\[\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{A}\\mathbf{x}) = 2\\mathbf{A}\\mathbf{x}\\]"
  },
  {
    "objectID": "slides/02-slides.html#derivative-rule-3-example",
    "href": "slides/02-slides.html#derivative-rule-3-example",
    "title": "Matrix Algebra Fundamentals",
    "section": "Derivative Rule 3: Example",
    "text": "Derivative Rule 3: Example\n\nLet \\(\\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 3 & 4 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)\n\n\nStep 1: Find \\(\\mathbf{A} + \\mathbf{A}'\\) \\[\\mathbf{A}' = \\begin{bmatrix} 2 & 3 \\\\ 1 & 4 \\end{bmatrix} \\mathbf{A} + \\mathbf{A}' = \\begin{bmatrix} 4 & 4 \\\\ 4 & 8 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#derivative-rule-3-example-cont.",
    "href": "slides/02-slides.html#derivative-rule-3-example-cont.",
    "title": "Matrix Algebra Fundamentals",
    "section": "Derivative Rule 3: Example (cont.)",
    "text": "Derivative Rule 3: Example (cont.)\nLet \\(\\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 3 & 4 \\end{bmatrix}\\) and \\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)\n\nStep 2: Apply the rule \\[\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{A}\\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}')\\mathbf{x} = \\begin{bmatrix} 4 & 4 \\\\ 4 & 8 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 4x_1 + 4x_2 \\\\ 4x_1 + 8x_2 \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/02-slides.html#symmetric-matrix-case",
    "href": "slides/02-slides.html#symmetric-matrix-case",
    "title": "Matrix Algebra Fundamentals",
    "section": "Symmetric Matrix Case",
    "text": "Symmetric Matrix Case\n\nExample: Let \\(\\mathbf{S} = \\begin{bmatrix} 3 & 2 \\\\ 2 & 5 \\end{bmatrix}\\) (symmetric)\n\n\nDerivative: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{S}\\mathbf{x}) = 2\\mathbf{S}\\mathbf{x} = 2\\begin{bmatrix} 3 & 2 \\\\ 2 & 5 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 6x_1 + 4x_2 \\\\ 4x_1 + 10x_2 \\end{bmatrix}\\)"
  },
  {
    "objectID": "slides/02-slides.html#general-form-mathbfbmathbfamathbfx",
    "href": "slides/02-slides.html#general-form-mathbfbmathbfamathbfx",
    "title": "Matrix Algebra Fundamentals",
    "section": "General Form: \\(\\mathbf{b}'\\mathbf{A}\\mathbf{x}\\)",
    "text": "General Form: \\(\\mathbf{b}'\\mathbf{A}\\mathbf{x}\\)\n\nRule: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{b}'\\mathbf{A}\\mathbf{x}) = \\mathbf{A}'\\mathbf{b}\\)\n\n\nNote: \\(\\mathbf{b}'\\mathbf{A}\\mathbf{x}\\) is a scalar, and \\(\\mathbf{b}\\) is treated as a constant vector"
  },
  {
    "objectID": "slides/02-slides.html#you-try-matrix-derivatives",
    "href": "slides/02-slides.html#you-try-matrix-derivatives",
    "title": "Matrix Algebra Fundamentals",
    "section": "You Try: Matrix Derivatives",
    "text": "You Try: Matrix Derivatives\n\nProblem: Find \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{B}\\mathbf{x})\\) where \\(\\mathbf{B} = \\begin{bmatrix} 1 & 0 \\\\ 2 & 3 \\end{bmatrix}\\)\n\n\nSolution: \\[\\mathbf{B}' = \\begin{bmatrix} 1 & 2 \\\\ 0 & 3 \\end{bmatrix}, \\quad \\mathbf{B} + \\mathbf{B}' = \\begin{bmatrix} 2 & 2 \\\\ 2 & 6 \\end{bmatrix}\\] \\[\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{B}\\mathbf{x}) = \\begin{bmatrix} 2 & 2 \\\\ 2 & 6 \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix} 2x_1 + 2x_2 \\\\ 2x_1 + 6x_2 \\end{bmatrix}\\]\n\n\n\n\n‚àí+\n04:00"
  },
  {
    "objectID": "slides/02-slides.html#summary-key-rules",
    "href": "slides/02-slides.html#summary-key-rules",
    "title": "Matrix Algebra Fundamentals",
    "section": "Summary: Key Rules",
    "text": "Summary: Key Rules\n\n\nLinear forms: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{a}'\\mathbf{x}) = \\mathbf{a}\\)\n\n\n\n\nQuadratic forms: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{A}\\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}')\\mathbf{x}\\)\n\n\n\n\nSymmetric case: \\(\\frac{\\partial}{\\partial \\mathbf{x}}(\\mathbf{x}'\\mathbf{A}\\mathbf{x}) = 2\\mathbf{A}\\mathbf{x}\\) when \\(\\mathbf{A} = \\mathbf{A}'\\)"
  },
  {
    "objectID": "slides/02-slides.html#connection-to-hat-matrix",
    "href": "slides/02-slides.html#connection-to-hat-matrix",
    "title": "Matrix Algebra Fundamentals",
    "section": "Connection to Hat Matrix",
    "text": "Connection to Hat Matrix\n\nThese rules are essential for deriving:\n\nNormal equations: \\(\\mathbf{X}'\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}'\\mathbf{y}\\)\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\)\nLeast squares solution: \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}\\)\n\n\n\nWe‚Äôll use these derivatives to minimize the sum of squared errors!"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " Policies",
    "section": "",
    "text": "This syllabus and the dates herein are subject to change.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#class",
    "href": "syllabus.html#class",
    "title": " Policies",
    "section": "Class",
    "text": "Class\nThis class is meant to be hands on. Therefore, you are responsible for reading pertinent material prior to each class.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": " Policies",
    "section": "Attendance",
    "text": "Attendance\nIf you feel unwell please do not come to class. All class material will be posted after class and I would be happy to meet outside of our class time to help you catch up if needbe.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#accessibility-policy",
    "href": "syllabus.html#accessibility-policy",
    "title": " Policies",
    "section": "Accessibility Policy",
    "text": "Accessibility Policy\nWake Forest University provides reasonable accommodations for students with disabilities. Academic accommodations are coordinated through the Center for Learning, Access, and Student Success (CLASS). If you would like to request accommodations for this course, you should contact CLASS as early in the semester as possible (class.wfu.edu,118 Reynolda Hall). Please contact me privately after sending notifications through the CLASS office Student Portal system. Retroactive accommodations will not be provided.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#how-to-get-help",
    "href": "syllabus.html#how-to-get-help",
    "title": " Policies",
    "section": "How to get help",
    "text": "How to get help\n\nDiscussion:\nAll course discussion will be on Canvas.\nThis is a place to post your course-related questions. I encourage you to try to answer each other‚Äôs questions. At the end of the semester, I will tally up the total number of questions answered and you can get up to 1 point extra credit on your final grade.\n\n\nMath & Stats Center:\n\nMake an appointment: https://mathandstatscenter.wfu.edu/",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#honor-code",
    "href": "syllabus.html#honor-code",
    "title": " Policies",
    "section": "Honor code",
    "text": "Honor code\nWake Forest University is committed to a culture of academic integrity. As a part of this community, you share the responsibility for creating a place of honesty, intellectual curiosity, and individual accountability. As you committed to with your honor pledge signature, you agree ‚Äúnot to deceive any member of the community; not to steal, cheat, or plagiarize on academic work; and not to engage in any other form of academic misconduct.‚Äù If you have questions about documenting your work, working with external sources, working with peers on assigned work, etc., consult with me as soon as possible. Instances of academic dishonesty will be referred to the Honor and Ethics Council.\n\nSharing code & responses\n\nYou may use online resources (e.g., StackOverflow, ChatGPT) for help. For projects, you must explicitly cite any borrowed or adapted code. This includes both directly copied code and code you modified for your own work. Un-cited reuse of code will be treated as plagiarism.\n\nFor exercises and in-class worked problems, you are welcome to use resources freely, but copying without understanding is strongly discouraged.\n\nRather than relying on someone else‚Äôs work, ask for help ‚Äî you are not alone in this course.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#course-components",
    "href": "syllabus.html#course-components",
    "title": " Policies",
    "section": "Course components",
    "text": "Course components\n\nExercises\nPractice problems designed to reinforce concepts. These are graded for completion.\n\n\nIn-class worked problems\nOn most Wednesdays, class time will be devoted to group work on the assigned exercise problems. Each week, you will be placed in groups of 2‚Äì3 students. One problem from the previous week‚Äôs homework will be randomly assigned to your group. One member of the group will then present the solution to the class. Over the course of the semester, each student is required to present at least three times.\nGrading Rubric:\n1 ‚Äì Minimal: Attempted presentation but showed little preparation; major errors or unclear explanation.\n2 ‚Äì Adequate: Mostly correct solution with a few minor errors.\n3 ‚Äì Strong: Fully correct solution; clear, accurate, and organized explanation; addressed the key steps of the solution; responded adequately to questions.\n4 ‚Äì Exceptional: Outstanding explanation that was clear, engaging, and insightful; demonstrated strong understanding and possibly connected the problem to broader course ideas.\nMost presentations will earn a 2 or 3, with 4s reserved for especially clear and helpful explanations.\n\n\nMidterm\nWe will have one in-class midterm.\n\n\nFinal Project\nA cumulative project worth integrating skills and knowledge from across the course.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": " Policies",
    "section": "Grading",
    "text": "Grading\nYour final grade will be determined as follows:\n\n\n\nComponent\nWeight\n\n\n\n\nExercises\n10%\n\n\nIn-class worked problems\n30%\n\n\nMidterm\n30%\n\n\nFinal Project\n30%\n\n\nTotal\n100%\n\n\n\nGrades conversion:\n\n\n\nLetter\nNumeric\n\n\n\n\nA\n&gt; 94\n\n\nA-\n90 - 94\n\n\nB+\n87 - 89\n\n\nB\n83 - 86\n\n\nB-\n80 - 82\n\n\nC+\n77 - 79\n\n\nC\n73 - 76\n\n\nC-\n70 - 72\n\n\nD+\n67 - 69\n\n\nD\n65 - 66\n\n\nF\nBelow 65",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  },
  {
    "objectID": "syllabus.html#late-missed-work",
    "href": "syllabus.html#late-missed-work",
    "title": " Policies",
    "section": "Late / missed work",
    "text": "Late / missed work\n\nLate work policy for labs:\n\nlate, but within 24 hours of due date/time: -50%\nany later: no credit\n\nNo make-up assessments will be given.\nAll regrade requests must be discussed with the professor within one week of receiving your grade. There will be no grade changes after the final class.",
    "crumbs": [
      "{{< fa calendar >}} Schedule",
      "Course Details",
      "Course Policies"
    ]
  }
]